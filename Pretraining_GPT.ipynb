{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842ddb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from torch.nn import functional as F\n",
    "from modules import GPTModel, TransformerBlock ,LayerNorm ,GELU ,FeedForward , MultiHeadAttention\n",
    "import modules\n",
    "import importlib\n",
    "importlib.reload(modules)\n",
    "\n",
    "from modules import GPTDatasetV1 , create_dataloader_v1 ,generate_next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77542e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text , tokenizer):\n",
    "    encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) ## add the batch dimension \n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def ids_token_to_text(ids , tokenizer) : \n",
    "    flat = ids.squeeze(0) ## remove batch dimension\n",
    "    decoded = tokenizer.decode(flat.tolist())\n",
    "    return decoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "191f71ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output : Every effort moves you  Stores CommanderTra Warm stereotypes eventual\n"
     ]
    }
   ],
   "source": [
    "text = \"Every effort moves you \"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_next_token(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(text,tokenizer) , \n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Model Output : {ids_token_to_text(token_ids,tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "254a64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"every effort moves\"\n",
    "text2 = \"I really like\"\n",
    "\n",
    "target1 = \"effort moves you forward\"\n",
    "target2 = \"really like chocolate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e57b86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],[40, 1107, 588]])\n",
    "targets = torch.tensor([[3626, 6100, 345 ], [1107, 588, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c659f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26f15453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
      "         [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
      "         [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217]],\n",
      "\n",
      "        [[-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
      "         [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
      "         [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]]])\n",
      "tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
      "          6.9776e-06, 1.8776e-05],\n",
      "         [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
      "          6.0103e-06, 1.3571e-05],\n",
      "         [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
      "          1.4094e-05, 1.3526e-05]],\n",
      "\n",
      "        [[1.2561e-05, 2.0537e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
      "          3.4784e-05, 1.4239e-05],\n",
      "         [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1206e-05,\n",
      "          1.1390e-05, 1.5559e-05],\n",
      "         [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
      "          5.8203e-05, 1.3698e-05]]])\n",
      "probs.shape : torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs.to(device))\n",
    "print(logits)\n",
    "probs = F.softmax(logits , dim=-1) ## probability of each token in the vocabulary\n",
    "print(probs)\n",
    "print(f\"probs.shape : {probs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4078f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probs,dim=-1,keepdim=True)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8270b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets batch 1 :  effort moves you\n",
      "outputs batch 1 :  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"targets batch 1 : {ids_token_to_text(targets[0],tokenizer)}\")\n",
    "print(f\"outputs batch 1 : {ids_token_to_text(token_ids[0].flatten(),tokenizer)}\")\n",
    "## ==> the model will produce random text because it is not trained yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28acc5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "target_probs_1 = probs[0,[0,1,2],targets[0]]\n",
    "print(target_probs_1)\n",
    "target_probs_2 = probs[1,[0,1,2],targets[1]]\n",
    "print(target_probs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a4bbafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "Average log probs : -10.793965339660645\n",
      "Average log probs : 10.793965339660645\n"
     ]
    }
   ],
   "source": [
    "log_probs = torch.log(torch.cat(((target_probs_1,target_probs_2))))\n",
    "print(log_probs)\n",
    "\n",
    "avg_log = torch.mean(log_probs)\n",
    "print(f\"Average log probs : {avg_log}\")\n",
    "\n",
    "neg_avg = avg_log * -1 \n",
    "print(f\"Average log probs : {neg_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1b3346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape : torch.Size([2, 3, 50257])\n",
      "targets.shape : torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"logits.shape : {logits.shape}\")\n",
    "print(f\"targets.shape : {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6806de96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_flatten.shape : torch.Size([6, 50257])\n",
      "targets_flatten.shape : torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flatten = logits.flatten(0,1)\n",
    "print(f\"logits_flatten.shape : {logits_flatten.shape}\")\n",
    "targets_flatten = targets.flatten(0,1)\n",
    "print(f\"targets_flatten.shape : {targets_flatten.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ac6e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = F.cross_entropy(logits_flatten , targets_flatten)\n",
    "print(loss) ## ==> same as the negative avg probability we already calculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf1d6754",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path,\"r\",encoding=\"utf-8\") as file : \n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14f7c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters :  20479\n",
      "Tokens     :  5145\n"
     ]
    }
   ],
   "source": [
    "total_chars  = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data)) \n",
    "print(f\"characters : \" , total_chars)\n",
    "print(f\"Tokens     : \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cead24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b07a924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfbeeff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader : \n",
      "\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "val loader : \n",
      "\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(f\"train loader : \\n\")\n",
    "for x,y in train_loader : \n",
    "    print(x.shape   , y.shape)\n",
    "\n",
    "print(f\"val loader : \\n\")\n",
    "for x,y in val_loader : \n",
    "    print(x.shape   , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12295399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch  = input_batch.to(device) \n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = F.cross_entropy(logits.flatten(0,1) , target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f33f6383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 10.793964385986328\n"
     ]
    }
   ],
   "source": [
    "loss = calc_loss_batch(inputs,targets,model,logits_flatten.device)\n",
    "print(f\"loss : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172108fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0 : \n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None : \n",
    "        num_batches = len(data_loader) ## if no batch size is given , we iterate over all batches \n",
    "    else : \n",
    "        num_batches = min(num_batches , len(data_loader))\n",
    "    \n",
    "    for i ,(input_batch , target_batch) in enumerate(data_loader) : \n",
    "        if i<num_batches : \n",
    "            loss = calc_loss_batch(input_batch , target_batch , model , device)\n",
    "            total_loss += loss.item() ##    sums loss for each batch\n",
    "        else : \n",
    "            break\n",
    "    return total_loss / num_batches ## average loss over all batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e70646ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss    : 10.987583584255642\n",
      "validdation loss : 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)\n",
    "    val_loss   = calc_loss_loader(val_loader,model,device)\n",
    "    \n",
    "print(f\"training loss    : {train_loss}\")\n",
    "print(f\"validdation loss : {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24c67377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss , val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bbf542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_print_sample(model,tokenizer,device,start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_next_token(model,idx=encoded,max_new_tokens=50,context_size=context_size)\n",
    "        decoded = ids_token_to_text(token_ids,tokenizer)\n",
    "        print(decoded.replace(\"\\n\" , \" \"))\n",
    "    model.train()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f835a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model,train_loader,val_loader,optimizer,device,\n",
    "                       num_epochs,eval_freq,eval_iter,start_context,tokenizer) : \n",
    "    train_losses , val_losses ,track_tokens_seen = [],[],[]\n",
    "    tokens_seen ,global_step = 0,-1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch , target_batch in train_loader : \n",
    "            optimizer.zero_grad() ## resets the gradients from the previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            loss.backward()  ## calculates loss gradients\n",
    "            optimizer.step() ## updates model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1 \n",
    "            \n",
    "            if global_step % eval_freq ==0 : \n",
    "                train_loss , val_loss = evaluate_model(\n",
    "                    model,train_loader,val_loader,device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train Loss {train_loss:.3f}  \"\n",
    "                      f\"Val Loss {val_loss:.3f}\")\n",
    "        generate_print_sample(model,tokenizer,device,start_context)\n",
    "    return train_losses , val_losses , track_tokens_seen\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42772908",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses , val_losses , track_tokens_seen = train_model_simple(\n",
    "                                model,train_loader,val_loader,optimizer,device,\n",
    "                                num_epochs,eval_freq=5,eval_iter=5,\n",
    "                                start_context=\"Every Effort moves you\",\n",
    "                                tokenizer=tokenizer\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbbfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "num_epochs = 10\n",
    "def plot_losses(epochs_seen , tokens_seen,train_losses,val_losses):\n",
    "    fig ,ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen , train_losses , label=\"Training Loss\")\n",
    "    ax1.plot(epochs_seen , val_losses ,linestyle=\"-.\", label=\"Validation Loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen,train_losses,alpha=0)\n",
    "    #ax1.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
    "plot_losses(epochs_tensor ,track_tokens_seen,train_losses,val_losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339bb1d6",
   "metadata": {},
   "source": [
    "Text Generation strategies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e386988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Encoding 'gpt2'>\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval() ## in order to turn off random components like dropout during inference \n",
    "print(tokenizer)\n",
    "\n",
    "token_ids = generate_next_token(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5de63f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text : \n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren Mortgage TT remember gard ACTIONSussedOND Land Engeleddedemate breaths proxies GalaxyForm\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output text : \\n {ids_token_to_text(token_ids , tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4956c039",
   "metadata": {},
   "source": [
    "Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bab8cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'closer', 1: 'every', 2: 'effort', 3: 'forward', 4: 'inches', 5: 'moves', 6: 'pizza', 7: 'toward', 8: 'you'}\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "\"closer\": 0,\n",
    "\"every\": 1,\n",
    "\"effort\": 2,\n",
    "\"forward\": 3,\n",
    "\"inches\": 4,\n",
    "\"moves\": 5,\n",
    "\"pizza\": 6,\n",
    "\"toward\": 7,\n",
    "\"you\": 8,\n",
    "}\n",
    "inv_vocab = {v:k for k,v in vocab.items()}\n",
    "print(inv_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "371e2194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "## Assuming the LLM is given \"Every effort moves you\" as input and generates the next output (based on the vocab fom the previous cell) \n",
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "probs = F.softmax(next_token_logits ,dim=-1)\n",
    "next_token_id = torch.argmax(probs).item()\n",
    "print(inv_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a97b7393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "## ===> Probabilistic selection from the softmax output (probabilities)\n",
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probs,num_samples=1).item()\n",
    "print(inv_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fc53aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probs) : \n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probs,num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i,freq in enumerate(sampled_ids) : \n",
    "        print(f\"{freq} x {inv_vocab[i]}\")\n",
    "print(print_sampled_tokens(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "704eba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    temperature scaling is used to change the distribution of the tokens : \n",
    "    temp > 1 ==> more uniformly distributed token probs\n",
    "    remp < 1 ==> more peaky (confident) distributed token probs\n",
    "\"\"\"\n",
    "def softmax_with_temperature(logits , temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return F.softmax(scaled_logits,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55444372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "temp = [1,0.1,5]\n",
    "scaled_probs = [softmax_with_temperature(next_token_logits,t) for t in temp]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "for i,t in enumerate(temp) :\n",
    "    rects = ax.bar(x+i*bar_width,scaled_probs[i],bar_width,label=f\"Temp = {t}\")\n",
    "ax.set_ylabel('Prob')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(),rotation=60)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "## as we can see , the higher the temperature is , the more the distribution is uniform ==> more words can be selected by the model\n",
    "## when training which reduces the probability of the model selecting the same token each time \n",
    "## but we should be careful because with very high temperatures the model can select tokens irrelevant to the correct context \n",
    "## (every effort move you pizza)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10d7da",
   "metadata": {},
   "source": [
    "Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98534ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top logits : tensor([6.7500, 6.2800, 4.5100])\n",
      "top positions : tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3 \n",
    "top_logits , top_pos = torch.topk(next_token_logits,top_k)\n",
    "print(f\"top logits : {top_logits}\")\n",
    "print(f\"top positions : {top_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75933f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new logits : tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(f\"new logits : {new_logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39ca7e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probs = F.softmax(new_logits,dim=0)\n",
    "print(topk_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc14adf",
   "metadata": {},
   "source": [
    "Final text generation function (combines probabilistic sampling , temperature scaling and top-k sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84616a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,idx,max_new_tokens,context_size,\n",
    "             temp=0.0,top_k=None,eos_id=None):\n",
    "    for _ in range(max_new_tokens) : \n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "        if top_k is not None : \n",
    "            top_logits , _ = torch.topk(logits,top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(\n",
    "                condition=logits < min_val,\n",
    "                input=torch.tensor(float('-inf')).to(logits.device),\n",
    "                other=logits\n",
    "            )\n",
    "        if temp > 0.0 : \n",
    "            logits = logits / temp\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "        else : \n",
    "            idx_next = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "        if idx_next == eos_id : \n",
    "            break\n",
    "        \n",
    "        idx = torch.cat((idx,idx_next),dim=1) \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1b57243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : Every effort moves you Laur similarity Aw137 Bethesda Lara anch republicquel Baton adultigans spotlightConsumer450\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\" , tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=15,\n",
    "    temp=1.4\n",
    "    )\n",
    "\n",
    "print(f\"output : {ids_token_to_text(token_ids , tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6ed17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x1a0c2744ef0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "\"https://raw.githubusercontent.com/rasbt/\"\n",
    "\"LLMs-from-scratch/main/ch05/\"\n",
    "\"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e0e93e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2 \n",
    "settings , params = download_and_load_gpt2(\n",
    "    model_size=\"124M\",models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "820b936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings : {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameters dictionary keys : dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Settings : {settings}\")\n",
    "print(f\"Parameters dictionary keys : {params.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3735ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token embedding weight tensor shape : (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f\"token embedding weight tensor shape : {params[\"wte\"].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64e8f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    \"gpt2_small (124M)\" : {\"emb_dim\":768 , \"n_layers\":12 ,\"n_heads\":12} , \n",
    "    \"gpt2_medium (355M)\" : {\"emb_dim\":1024 , \"n_layers\":24 ,\"n_heads\":16} , \n",
    "    \"gpt2_large (774M)\" : {\"emb_dim\":1280 , \"n_layers\":36,\"n_heads\":20} , \n",
    "    \"gpt2_xl (1558M)\" : {\"emb_dim\":1600 , \"n_layers\":48 ,\"n_heads\":25} , \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24a2ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': True}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2_small (124M)\"\n",
    "new_config = GPT_CONFIG_124M.copy()\n",
    "new_config.update(models_config[model_name])\n",
    "new_config.update({\"context_length\":1024})\n",
    "new_config.update({\"qkv_bias\":True})\n",
    "print(new_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90776132",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTModel(new_config)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left,right):\n",
    "    if left.shape != right.shape : \n",
    "        raise ValueError(f\" Shape mismatch .Left: {left.shape}  Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253afe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the weights into our gpt model\n",
    "import numpy as np \n",
    "def load_weights_into_gpt(gpt , params) : \n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight,params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight,params[\"wte\"])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])) : \n",
    "        ## Attention Q,K,V weights\n",
    "        q_w,k_w,v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"] , 3 , axis=-1)\n",
    "        gpt.trf_blocks[b].MHattention.w_q.weight =assign(gpt.trf_blocks[b].MHattention.w_q.weight ,q_w.T)\n",
    "        gpt.trf_blocks[b].MHattention.w_k.weight =assign(gpt.trf_blocks[b].MHattention.w_k.weight ,k_w.T)\n",
    "        gpt.trf_blocks[b].MHattention.w_v.weight =assign(gpt.trf_blocks[b].MHattention.w_v.weight ,v_w.T)\n",
    "        ## Attention Q,K,V bias\n",
    "        q_b , k_b , v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"],3,axis=-1)\n",
    "        gpt.trf_blocks[b].MHattention.w_q.bias =assign(gpt.trf_blocks[b].MHattention.w_q.bias ,q_b)\n",
    "        gpt.trf_blocks[b].MHattention.w_k.bias =assign(gpt.trf_blocks[b].MHattention.w_k.bias ,k_b)\n",
    "        gpt.trf_blocks[b].MHattention.w_v.bias =assign(gpt.trf_blocks[b].MHattention.w_v.bias ,v_b)\n",
    "        ## Attention out_proj weights and bias\n",
    "        gpt.trf_blocks[b].MHattention.out_proj.weight = assign(gpt.trf_blocks[b].MHattention.out_proj.weight,params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].MHattention.out_proj.bias   = assign(gpt.trf_blocks[b].MHattention.out_proj.bias,params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        ## feed forward layer weights and bias  \n",
    "        gpt.trf_blocks[b].ffn.layers[0].weight = assign(gpt.trf_blocks[b].ffn.layers[0].weight,params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ffn.layers[0].bias   = assign(gpt.trf_blocks[b].ffn.layers[0].bias,params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ffn.layers[2].weight = assign(gpt.trf_blocks[b].ffn.layers[2].weight,params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ffn.layers[2].bias   = assign(gpt.trf_blocks[b].ffn.layers[2].bias,params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].layer_norm_1.scale = assign(gpt.trf_blocks[b].layer_norm_1.scale,params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].layer_norm_1.shift = assign(gpt.trf_blocks[b].layer_norm_1.shift,params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].layer_norm_2.scale = assign(gpt.trf_blocks[b].layer_norm_2.scale,params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].layer_norm_2.shift = assign(gpt.trf_blocks[b].layer_norm_2.shift,params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "        \n",
    "        gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "        gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "        \n",
    "        gpt.out_head.weight  = assign(gpt.out_head.weight,  params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_into_gpt(gpt,params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "85b9ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(138)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\" , tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    temp=2,\n",
    "    top_k=30,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5ec9e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output :\n",
      " Every effort moves you forward on your path!\"\n",
      "\n",
      "You won \"The battle of a battlefield of the battle arena!\"! A battle\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output :\\n {ids_token_to_text(token_ids , tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c87756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation set losses of the GPTModel with the pretrainedweights from OpenAI on the â€œThe Verdictâ€ dataset: \n",
      "training loss = 3.639 -- validation loss = 3.560\n"
     ]
    }
   ],
   "source": [
    "train_loss , val_loss = evaluate_model(\n",
    "    model=gpt,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    eval_iter=5\n",
    ")\n",
    "print(f\"Training and validation set losses of the GPTModel with the pretrained\"\n",
    "      f\"weights from OpenAI on the â€œThe Verdictâ€ dataset: \\ntraining loss = {train_loss:.3f} -- validation loss = {val_loss:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
