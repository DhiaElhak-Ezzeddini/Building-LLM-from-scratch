{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080505ec",
   "metadata": {},
   "source": [
    "Classification Fine-Tuning (text messages --> Spam / Not Spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a898cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_dataset(url,zip_path,extracted_path,data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f'{data_file_path} already exists. Skipping download and extraction.')\n",
    "        return\n",
    "    with urllib.request.urlopen(url) as response : ## downloads the file\n",
    "        with open(zip_path,\"wb\") as out_file : \n",
    "            out_file.write(response.read())\n",
    "    with zipfile.ZipFile(zip_path,\"r\") as zip_ref : \n",
    "        zip_ref.extractall(extracted_path)\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path , data_file_path)\n",
    "    print(f\"File Downloaded and saved as {data_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_unzip_dataset(url,zip_path,extracted_path,data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4221dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"sms_spam_collection/SMSSpamCollection.tsv\" ,sep=\"\\t\",header=None,names=[\"Label\" , \"Text\"])\n",
    "print(df[\"Label\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef71a8",
   "metadata": {},
   "source": [
    "Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def61b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Balancing the dataset : 747 spam , 4825 ham\n",
    "def balance_dataset(df) : \n",
    "    num_spam = df[df[\"Label\"]==\"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"]==\"ham\"].sample(num_spam,random_state=123)\n",
    "    balanced = pd.concat([ham_subset , df[df[\"Label\"]==\"spam\"]])\n",
    "    return balanced\n",
    "\n",
    "balanced_df = balance_dataset(df) ## balanced dataset \n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\":0,\"spam\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc14497",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting the dataset \n",
    "def split_dataset(df,train_frac,val_frac) : \n",
    "    df = df.sample(\n",
    "        frac=1 , random_state=123\n",
    "    ).reset_index(drop=True)\n",
    "    train_end = int(len(df)*train_frac)\n",
    "    validation_end = train_end + int(len(df) * val_frac)\n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    return train_df , val_df , test_df\n",
    "train_df , val_df , test_df = split_dataset(balanced_df , 0.7,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\" , index=None)\n",
    "val_df.to_csv(\"val.csv\" , index=None)\n",
    "test_df.to_csv(\"test.csv\" , index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2688f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self,csv_file,tokenizer,max_length=None , pad_token_id=50256) : \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.texts_encoded = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "        if max_length is None : \n",
    "            self.max_length = self._longest_encoded_text()\n",
    "        else : \n",
    "            self.max_length = max_length \n",
    "            self.texts_encoded = [\n",
    "                text_encoded[:self.max_length] for text_encoded in self.texts_encoded ## truncate text if it is longer than the specified max length \n",
    "            ]\n",
    "        self.texts_encoded = [ ## add padding to texts to mach the longest text in the dataset\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.texts_encoded\n",
    "        ]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.texts_encoded[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded,dtype=torch.long),\n",
    "            torch.tensor(label,dtype=torch.long)\n",
    "        )\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def _longest_encoded_text(self) : \n",
    "        max_length = 0 \n",
    "        for encoded_text in self.texts_encoded : \n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length : \n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\"train.csv\" , tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\"val.csv\" , tokenizer,max_length=train_dataset.max_length)\n",
    "test_dataset = SpamDataset(\"test.csv\" , tokenizer,max_length=train_dataset.max_length)\n",
    "print(val_dataset.max_length)\n",
    "print(test_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ff8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de172c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_batch , target_batch in val_loader : \n",
    "    pass\n",
    "print(f\"Input batch shape  : {input_batch.shape}\")\n",
    "print(f\"Target batch shape : {target_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c95b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(train_loader)} : training batches\")\n",
    "print(f\"{len(val_loader)}  : validation batches\")\n",
    "print(f\"{len(test_loader)}  : test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb7efd",
   "metadata": {},
   "source": [
    "Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = \"gpt2_small (124M)\"\n",
    "input_prompt = \"Every effort moves you\"\n",
    "base_config = {\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":1024,\n",
    "    \"drop_rate\":0.0,\n",
    "    \"qkv_bias\":True\n",
    "}\n",
    "\n",
    "models_config = {\n",
    "    \"gpt2_small (124M)\" : {\"emb_dim\":768 , \"n_layers\":12 ,\"n_heads\":12} , \n",
    "    \"gpt2_medium (355M)\" : {\"emb_dim\":1024 , \"n_layers\":24 ,\"n_heads\":16} , \n",
    "    \"gpt2_large (774M)\" : {\"emb_dim\":1280 , \"n_layers\":36,\"n_heads\":20} , \n",
    "    \"gpt2_xl (1558M)\" : {\"emb_dim\":1600 , \"n_layers\":48 ,\"n_heads\":25} , \n",
    "}\n",
    "base_config.update(models_config[chosen_model])\n",
    "print(base_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef4923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from modules import  GPTModel , load_weights_into_gpt\n",
    "model_size = chosen_model.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "print(f\"model size : \",model_size)\n",
    "settings , params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066238a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTModel(base_config)\n",
    "load_weights_into_gpt(gpt,params)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ba3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules\n",
    "import importlib\n",
    "importlib.reload(modules)\n",
    "from modules import generate , text_to_token_ids , ids_token_to_text , generate_next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ada03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = generate(\n",
    "    model=gpt,\n",
    "    idx = text_to_token_ids(input_prompt,tokenizer),\n",
    "    context_size=base_config[\"context_length\"],\n",
    "    max_new_tokens=20,\n",
    "    temp=1.4,\n",
    "    top_k=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model output : \\n{ids_token_to_text(ids,tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0253bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    before fine-tunning the model , let's test its capacity to follow instructions\n",
    "    ==> the result shows that the model is struggling with the input prompt it was given because it lacks the ability to understand and \n",
    "    follow instructions , which is done via fine-tunning as we are going to do next.\n",
    "\"\"\"\n",
    "text_2 = (\n",
    "\"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "\" 'You are a winner you have been specially\"\n",
    "\" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_next_token(\n",
    "model=gpt,\n",
    "idx=text_to_token_ids(text_2, tokenizer),\n",
    "max_new_tokens=50,\n",
    "context_size=base_config[\"context_length\"]\n",
    ")\n",
    "print(ids_token_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpt.out_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf48fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    for our classification task we need the output to be the probabilities between two classes 0:ham , 1:spam\n",
    "    to do that we need to map the output in the out_head layer from dim=768 to dim=2 (instead of 50257)\n",
    "    this is called Fine-tuning selected since we are fine-tuning only the last layer (near the output)\n",
    "    in order to do this we need to \"freeze\" the model : make all layers non-trainable\n",
    "\"\"\"\n",
    "n_classes = 2\n",
    "torch.manual_seed(123)\n",
    "gpt.out_head = torch.nn.Linear( ## ==> requires_grad = True ====> this layer is trainable\n",
    "    in_features=base_config[\"emb_dim\"],\n",
    "    out_features=n_classes\n",
    ")\n",
    "print(gpt.out_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec886d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Last transformer blocks and the final normalization layer are also trainable (this may add more efficiency to our model)\n",
    "\n",
    "for param in gpt.trf_blocks[-1].parameters() : \n",
    "    param.requires_grad = True\n",
    "for param in gpt.final_norm.parameters() : \n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(f\"Inputs : {inputs}\")\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c216ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad() : \n",
    "    outputs = gpt(inputs.to(device))\n",
    "print(f\"Output : {outputs}\")\n",
    "print(f\"Output shape : {outputs.shape}\") ## similar input would have [1,4,50257] as output shape \n",
    "print(f\"Last output token : {outputs[:,-1,:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eef7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(outputs[:,-1,:] , dim=-1)\n",
    "print(f\"probs : {probs}\")\n",
    "label = torch.argmax(probs)\n",
    "print(f\"class : {label.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data_loader , model , device ,  num_batches = None) : \n",
    "    model.eval()\n",
    "    correct_preds , num_examples = 0,0\n",
    "    if num_batches is None : \n",
    "        num_batches = len(data_loader)\n",
    "    else : \n",
    "        num_batches = min(len(data_loader), num_batches)\n",
    "    for i , (input_batch , target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches : \n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch= target_batch.to(device)\n",
    "            with torch.no_grad() : \n",
    "                logits = model(input_batch)[:,-1,:]\n",
    "            preds = torch.argmax(logits , dim=-1)\n",
    "            num_examples += preds.shape[0]\n",
    "            correct_preds += (preds == target_batch).sum().item()\n",
    "        \n",
    "        else : \n",
    "            break\n",
    "    return correct_preds / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c163cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "gpt.to(device)\n",
    "train_accuracy = calc_accuracy(train_loader , gpt,device,num_batches=10)\n",
    "val_accuracy = calc_accuracy(val_loader , gpt,device,num_batches=10)\n",
    "test_accuracy = calc_accuracy(test_loader , gpt,device,num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy : {train_accuracy}\")\n",
    "print(f\"Validation accuracy : {val_accuracy}\")  \n",
    "print(f\"Test accuracy : {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a201dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the Loss over all the input batch : \n",
    "def calc_loss_batch(input_batch,target_batch,model,device) : \n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:,-1,:]\n",
    "    loss = torch.nn.functional.cross_entropy(logits , target_batch)\n",
    "    return loss \n",
    "\n",
    "### Calculating the Loss in the data loader :\n",
    "def calc_loss_loader(data_loader,model,device,num_batches=None) :\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0 : \n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None : \n",
    "        num_batches = len(data_loader)\n",
    "    else : \n",
    "        num_batches = min(num_batches , len(data_loader))\n",
    "    for i , (input_batch , target_batch) in enumerate(data_loader) : \n",
    "        if i<num_batches : \n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            total_loss += loss.item()\n",
    "        else : \n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107dc401",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad() : \n",
    "    train_loss = calc_loss_loader(train_loader,gpt,device,num_batches=5)\n",
    "    val_loss   = calc_loss_loader(val_loader,gpt,device,num_batches=5)\n",
    "    test_loss  = calc_loss_loader(test_loader,gpt,device,num_batches=5)\n",
    "print(f\"Training Loss   : {train_loss:.3f}\")\n",
    "print(f\"Validation Loss : {val_loss:.3f}\")  \n",
    "print(f\"Test Loss       : {test_loss:.3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss , val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter):\n",
    "    train_losses , val_losses , train_accs , val_accs = [],[],[],[]\n",
    "    ex_seen , global_step = 0,-1\n",
    "    for epoch in range(num_epochs) : \n",
    "        model.train() \n",
    "        for input_batch , target_batch in train_loader : \n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ex_seen += input_batch.shape[0]\n",
    "            global_step += 1 \n",
    "            \n",
    "            if global_step % eval_freq ==0 : \n",
    "                train_loss , eval_loss = evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
    "                val_losses.append(eval_loss)\n",
    "                train_losses.append(train_loss)\n",
    "                print(f\"Ep {epoch+1} (step {global_step:06d}) :\"\n",
    "                      f\"Train Loss {train_loss:.3f}   \"\n",
    "                      f\"Validation Loss {eval_loss:.3f}\")\n",
    "        train_accuracy = calc_accuracy(train_loader,model,device,num_batches=eval_iter)\n",
    "        val_accuracy   = calc_accuracy(val_loader,model,device,num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        \n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "        \n",
    "    return train_losses , val_losses , train_accs , val_accs , ex_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(),lr=5e-5,weight_decay=0.1)\n",
    "num_epochs=5\n",
    "\n",
    "train_losses , val_losses , train_accs , val_accs , ex_seen = \\\n",
    "    train_classifier_simple(gpt,train_loader,val_loader,optimizer,device\n",
    "                            ,num_epochs,eval_freq=50,eval_iter=5)\n",
    "\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time ) / 60\n",
    "print(f\"Training time : {exec_time:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_values(epochs_seen,examples_seen,train_values,val_values,label=\"loss\") : \n",
    "    fig , ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen,train_values,label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen,val_values,linestyle='-.',label=f\"validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen,train_values,alpha=0)\n",
    "    ax2.set_xlabel(\"examples seen\")\n",
    "    fig.tight_layout()        \n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0,ex_seen,len(train_losses))\n",
    "plot_values(epochs_tensor,examples_seen_tensor,train_losses,val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b83072",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0,ex_seen,len(train_accs))\n",
    "plot_values(epochs_tensor,examples_seen_tensor,train_accs,val_accs,label=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1caad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = calc_accuracy(train_loader,gpt,device)\n",
    "val_accuracy = calc_accuracy(val_loader,gpt,device)\n",
    "test_accuracy = calc_accuracy(test_loader,gpt,device)\n",
    "print(f\"Training Accuracy   : {train_accuracy:.2f}\")\n",
    "print(f\"Validation Accuracy : {val_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy       : {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text,model,tokenizer,device,max_length = None ,pad_token_id=50256):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "    input_ids = input_ids[:min(len(input_ids),supported_context_length)]\n",
    "    input_ids +=  [pad_token_id] * (max_length  - len(input_ids)) ## pads sequences to the longest sequence\n",
    "    input_tensor = torch.tensor(input_ids , device=device).unsqueeze(0) ## adds batch dimension\n",
    "    with torch.no_grad() : \n",
    "        logits = model(input_tensor)[:,-1,:]\n",
    "    predicted_label = torch.argmax(logits,dim=-1).item()\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = (\n",
    "\"You are a winner you have been specially\"\n",
    "\" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "print(classify_review(text_1,gpt,tokenizer,device,max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2 = (\n",
    "\"Hey, just wanted to check if we're still on\"\n",
    "\" for dinner tonight? Let me know!\"\n",
    ")\n",
    "print(classify_review(text_2,gpt,tokenizer,device,max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gpt.state_dict() , \"review_classifier.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
