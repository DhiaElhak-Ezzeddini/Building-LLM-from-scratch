{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a845a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@ Overview of the model architecture @@@@@ \n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb    = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
    "        self.pos_emb    = nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
    "        self.drop_emb   = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"] , cfg[\"vocab_size\"],bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self,in_idx) : ## in_idx is the tokenized input of shape [batch_size , seq_len]\n",
    "        batch_size , seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len,device=in_idx.device))\n",
    "        \n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return x\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97fabf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch_test = []\n",
    "text1 = \"Every effort moves you\"\n",
    "text2 = \"Every day holds a\"\n",
    "batch_test.append(torch.tensor(tokenizer.encode(text1)))\n",
    "batch_test.append(torch.tensor(tokenizer.encode(text2)))\n",
    "batch_test = torch.stack(batch_test,dim=0)\n",
    "print(batch_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b04a4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape (batch_size , seq_len , vocab_size):  torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257, # Vocabulary size\n",
    "\"context_length\": 1024, # Context length ==> after 1024 tokens the model can predict the next token \n",
    "\"emb_dim\": 768, # Embedding dimension\n",
    "\"n_heads\": 12, # Number of attention heads\n",
    "\"n_layers\": 12, # Number of layers\n",
    "\"drop_rate\": 0.1, # Dropout rate\n",
    "\"qkv_bias\": False # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch_test)\n",
    "print(f\"output shape (batch_size , seq_len , vocab_size): \", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c199e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3710, 0.0000, 0.5695, 0.6726, 0.2738, 0.6135],\n",
      "        [0.3424, 0.0000, 0.2633, 0.3311, 0.2569, 0.2686]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "\n",
      "bbefore layer normalization\n",
      "\n",
      "mean  tensor([[0.4167],\n",
      "        [0.2437]], grad_fn=<MeanBackward1>)\n",
      "var  tensor([[0.0647],\n",
      "        [0.0156]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Layer Normalization , it consists on normalizing the output of a given layer (previous layer)\n",
    "## making the distribution of the overall output of the activations (Neurons) ~ N(0,1) ==> Stabilizing the training\n",
    "torch.manual_seed(193)\n",
    "batch_example = torch.rand(2,5)\n",
    "layer = nn.Sequential(nn.Linear(5,6),nn.ReLU())\n",
    "out   = layer(batch_example)\n",
    "print(out) \n",
    "print(f\"\\nbbefore layer normalization\\n\")\n",
    "mean = out.mean(dim=-1,keepdim=True)\n",
    "var  = out.var(dim=-1,keepdim=True)\n",
    "print(f\"mean \",out.mean(dim=-1,keepdim=True))\n",
    "print(f\"var \",out.var(dim=-1,keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5306c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "after normalization\n",
      "\n",
      "tensor([[-0.1796, -1.6379,  0.6002,  1.0056, -0.5616,  0.7734],\n",
      "        [ 0.7907, -1.9519,  0.1565,  0.6997,  0.1053,  0.1996]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "mean tensor([[     0.0000],\n",
      "        [    -0.0000]], grad_fn=<MeanBackward1>)\n",
      "var tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1,keepdim=True)\n",
    "var = out_norm.var(dim=-1,keepdim=True)\n",
    "print(f\"\\nafter normalization\\n\")\n",
    "print(out_norm)\n",
    "print(f\"mean {mean}\")\n",
    "print(f\"var {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7c8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "## building the layer normalization class \n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 ## since we are dividing by the square root of the variance , we use eps to prevent division by zero \n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        ## scale and shift are learned parameters that the model can update if this can enhance the training\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        var = x.var(dim=-1,keepdim=True,unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b485dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance\n",
      " tensor([[0.9996],\n",
      "        [0.9999]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1,keepdim=True)\n",
    "var = out_ln.var(dim=-1,keepdim=True,unbiased=False)\n",
    "print(f\"Mean\\n {mean}\")\n",
    "print(f\"Variance\\n {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61dc65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "GELU function is known by its smoothness , as for for ReLU , that turn any negative value into zero\n",
    "making any neuron with negative output unable to contribute to the training , GELU can acccept a small range of negative values \n",
    "allowing to more neurons to contribute in the training process. \n",
    "\"\"\"\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return 0.5*x*(1 + torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi))*(x+0.044715*torch.pow(x,3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0591f8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABd/UlEQVR4nO3dCVhUVRsH8D/7pqC4gAru+y6QppZLudviV5mf5VKplWlpmqV+ZpmVlZWWmkubZZpmZZaZaZapqangvuWOKAJugOzLfM97cAhwUIcB7p07/9/zXJm53Jk5Z0bumXPPed/jZDKZTCAiIiIiIrKBsy0PJiIiIiIiEuxYEBERERGRzdixICIiIiIim7FjQURERERENmPHgoiIiIiIbMaOBRERERER2YwdCyIiIiIishk7FkREREREZDN2LIiIiIiIyGbsWBBZ8Oqrr8LJyUmT1164cKF67VOnTpX6a2dmZuLFF19EcHAwnJ2d0adPH+iRlu8RETm2xx57DDVr1nS4tunq1asYOnQoAgMDVRlGjx4NPdLyPSJ2LBzSyZMnMXLkSNSvXx/e3t5qa9y4MUaMGIG9e/da/AMtbDt//rw6Tr7gyf1333230NeVE/E999xj8Xc7d+5Uj5cvjKUlOTlZ1W/Dhg3QwptvvokffvgBevLZZ59h+vTpeOihh/DFF1/g+eef17Q8enyPiIzM3Gk3b66urqhWrZr6Mn327NkiPaecY+W5vv3220KPkd9Lu2SJPE5+X5rn6nPnzqn2Yffu3ShtWrdNNzofy/+P4cOHY9GiRRg4cKBmZdHre0SAq9YFoNK1atUq9OvXTzUWjz76KFq0aKGuTB8+fBjff/895s6dqzoeNWrUyPc42V+mTJnrnq9cuXKwV3JimjJlirrdqVOnfL+bNGkSxo8fX+InafkCX3BUQE7W//3vf+Hh4YHS9vvvv6svETNmzIAe6PE9InIEr732GmrVqoXU1FRs27ZNfaHcvHkz9u/fD09PTxiddCykfZALYi1btsz3u48//hjZ2dmGbZtu1D7cfvvteOWVV6A1vb5HxI6FQzl+/Lj6MiadhvXr16NKlSr5fv/222/jo48+Uh2NguTLXcWKFeEopOMlmxZcXFzUpoXY2Fi76Cxq+R4ROYKePXsiLCxM3ZbpL3L+lzbixx9/xMMPPwxH5ubm5pBtk7QPMrtB77R8j4hToRzKO++8g6SkJHz++efXdSqE/CE+99xzan69Xl26dAkvvPACmjVrpkZQfH19VQO4Z8+e646VK20yVCpTvuQKm9T5gQceUB0smbpVqVIldZxc9TAP+8vxluZoNm3aFJ07d77uNeSqlVzhl46XmUwHa9euHSpUqAAvLy+EhoZeNwVAnls+C5luZH5tmWpwo/gB6fQ1adJEXaWvWrWqmrp25cqVfMfIlRsp68GDB1V5ZZqblE8++xsxT2X7448/cODAgdwyyTCzeRpDwSFn82PyTl+TOsjnIlMmZJRBbsv7LJ9ZVlbWde/dBx98oD5L+XzkuB49eqhpcXp8j4gc2Z133ql+yvkzLxntlvOfv7+/+juWzoh0PrRw+vRpPPPMM2jQoIE698o5uG/fvhZjseS8IFM9ZURCzhdBQUEYNGgQLly4oM51t912mzru8ccfzz3/mM91eWMsMjIyVN3luIISEhLUeyLnP5Geno7JkyerNsHPzw8+Pj7qfZXzrpm1bZM5Nm7q1KmoU6eOqouUbeLEiUhLS7M4HVlGnlq3bq3KVrt2bXz55Zc3fF/NbYDMZvj5559zyyRlLexcbKndsObcW5ztd2m8R/QvdiwcbBpU3bp10aZNmyJ9oZcTbt6t4Be20nDixAk1517+8N9//32MGzcO+/btQ8eOHdXQtZl8iZVj5KQjJ/H33nsPo0aNQnx8vBrKl5OSTO8S//nPf9R8UdnkxGWJTB/buHFjbkyJmZx85HVlJMhMviy3atVKTSWQqTzSYZPGTU7IZvJacnKTRsX82k899VSh9ZYTpXxJli/LUpcHH3wQ8+fPR7du3VTDltfly5fVF3SZ5ibHNmzYEC+99BJ++eWXQp9f3g8pgxwrDay5TI0aNYK15L3v3r27atSlkyWfjZRjwYIF+Y4bMmSICv6TjqxcCZWhazmJy7QLPb5HRI7M/MWxfPnyufvkIoRMjTl06JD6+5W/JfmyLBcVVqxYUepl3LFjB7Zs2aLOxx9++CGefvppNTovX2hl6kzeIGQ5r8yaNUudH+ScLcdKJykqKkqd9+T8LZ588snc80+HDh0sjl5IGyLtknQc8pJ98sXV3D5IR+OTTz5R5ZFznpyz4uLi1PnSHMthbdtkHlGSDktISIiaxirn3GnTpuVrl8yOHTumOoJdu3ZVn5d8ntJRks+yMPJ+SBlk1EqmhZnLZP5yb41bOfcWd/tdGu8R5WEihxAfH2+Sj7tPnz7X/e7y5cumuLi43C05OTn3d6+88op6nKWtQYMGucedPHlS7Zs+fXqhZahRo4apd+/eFn+3Y8cO9fjPP//8hvVITU01ZWVl5dsnr+3h4WF67bXXcvd99tln6vnef//9654jOztb/ZS6yjFSx4LM9TY7cuSIuj9r1qx8xz3zzDOmMmXK5HvP8t4W6enppqZNm5ruuuuufPt9fHxMgwcPvu615T2Q15J6idjYWJO7u7upW7du+eo+e/ZsdZzU1axjx45q35dffpm7Ly0tzRQYGGh68MEHTTcjj2/SpEm+fX/88Yd6TvmZl/kzz/uZSX1kX97PQrRq1coUGhqae//3339Xxz333HOFfj56fY+IjMz8t/Xbb7+pc+SZM2dM3377ralSpUrqPCv3ze6++25Ts2bN1Hk5799vu3btTPXq1bvuHLJ8+fJCX1d+P2LECIu/k8dZOgcVVPDcK7Zu3Xrd3/vkyZPVvu+//77Q88+N2iQ5J0l7Zvbrr7+qY3/66ad8x/Xq1ctUu3bt3PuZmZnqXFOw/Q0ICDA98cQTufusaZt2796t7g8dOjTfcS+88ILaL+daMymz7Nu4cWPuPjl3yuc6duxY081YasMLnotv1G7c6rm3uNvv0nyPyGTiiIWDkCslwlIAtlw9kSsA5m3OnDnXHfPdd99h3bp1+TaZUlXa5Aq2OQZErmpcvHhR1UmGviMiIvKVV66uPPvss9c9R1HS0MlwrFypWbZsWe4+eX2Z4nTvvfeqYXezvLfl6oxcZZGrY3nLZ43ffvtNXQmTq/t541+GDRumpoLlHQkR8n4MGDAg9767u7sa0pXRntIiV//ykvrnfX35fORzsBQEWJTPxx7fIyI969Kli2oPZERRrt7KSIRMcZIRTfMotgTzSrxFYmJi7ki2nJPlCvzRo0eLnEWqqPKee2WUUsoio/QSN1awfZAr5nK1uzjOP3fddZdqb/K2D3Lul3ZSRrvNJC5MzjXmqaDyHsoUHZk+VtT2YfXq1ernmDFj8u0fO3as+lnw3CcxEuZpbUI+Y2k/S+vcdyvn3uJuv+3tPbJ3jG5xEGXLls0dAi5IpotIwxATE5PvDz4vGQIujeDtm500zPPyZS69zPfMO29fpt6YyTxMOREUZwCXNBAyJ1MaS5kXKnNHJZgtb8NhnnL2+uuvq6HtvPM3i5pXW+YNC6lPXnJClrmf5t+bScNf8LVkKLdgKuGSYo6XKPj60tDm/XxkypLMTS4O9vYeEemdXGCSCypyYUTSUMtU0LxZ2GS6iAw0vPzyy2qzRM6Pcq4sLjc7h6akpKjpLXLRS87TOQMhOaQeec8/MlWyuEg7I8+3ZMkSdc6X90myLErnpmD7IDFjMr1Gpl3lnaIpGbiKQs5tcjFFOlB5yVoT0qEqeO6rXr36dc9R8Pxckm7l3Fvc7be9vUf2jh0LByGBYhL8JPMTCzLHXJT0YmPyhVNO/JaY57/eLI2hxCxII/bEE0+oQCz5YionDLlSXZLp/4Q0EBMmTMDy5cvV633zzTfqfZX5omabNm3Cfffdpzpi0vmR91zm4EpDJ41OaSgsW1LeRrY4GvOCwdg3e309Ke73iMho5CqyOSuUxEzccccdeOSRR3DkyBF11dl8vpXAZBmhsKTgF7kbkS/jtrYPcoVbzrVyfm7btq06P8v5S+bRl3T7IK8hF+kkVkDeL2kfJH5ARkbMvvrqKzVXX34v8YGVK1dW5yLpDBUMirfWrV640mv7UBrnXq3eI0fDjoUD6d27twoc2759u2o0SpukuZVsEJZIY2U+5kZk6pFkk/j000/z7ZdA8rwjKpL54e+//1ZXhApLDWjtCIJcUZL3TYa7ZSEnuSIlDUTeq3gyhCuN36+//ppvv6VpY7f6+ub3RN4jufpuJlN/ZNRGpiyUJHOwZsFg/YJXeawhn4+8RzIV4EajFvbyHhEZmfnLr5x7Z8+erQK1zX9ncn4tjr8v+Rs2twO2tA+DBw9WIwJ5swsVPHfJ+cfSRTZb2ge5mCQXkqR9kE6YTBP73//+d1355H2TtiPv8xecEmrNa8t7Ip0mmXqWN9mGzECQet/sPdNr+1Cc7bfW75GjYYyFA3nxxRdVeje52i9/UKXdG+/Vq5fKuFFwJWUZOpYOj1y9kYwNN2vgCpZTRhAKzuWVYWmZ7yuNYEHmx8t7IazJbiWjFpK1SKYGyPMXHOaW8skJL+/VGhkJsrR6tMxZvpXXlkZbpvRIlpO8dZfOlQzvS4exJMlJV+olUyHykhGZopLPR+piXuAor7x1tJf3iMjoJBZPLqzMnDlTfVmX87Xsk6v00dHR1x0v2Y6sbR/k3BoeHp5vv/z9L168WMW4ydQVa9sHyfxU8Oq5nH8kRbmlzFXmx8u5x/z6t0JGziUW5aefflIZiiR2wlL7kPc1hHyB3rp1a77jrGmb5H0T8rnkJVkTRUmf+6QTIPK2D/J+F8wCaI3ibr+1fo8cDUcsHEi9evXUdJz+/fur+YvmlbflD1Wu6srv5ORoDs4reKXFUuC3pGMLCAjIvS+p/aTRKUiu7EvaPvlCLqlXpXMjKVkluE6u8MjVI8kTbQ5sK4ykoJM0gJIzXNaKkFSz0ujkvUotJB+5PJ8Ea8kIjQRiyZoIEuQrec7vv/9+FegnQVry+jKXWK6cS45t2QojgYoy9C+bHF/wSp2coORkJdOjZNqAzDGWucoyJaDg/H1JoyflkeMl3kBGRCylApZ4BZmCJV/C5XllqpVcwZMv9pJrvbC4mOIi0wnkM5MGWjpN0pBIHInUrajkyqesni0dAbmKJPWSK0oylUx+JyNC9vQeETkCmb4j5wJZu0ASNMi5Ta7Oy1o0kihBzsNy0Uq+KMtFpILrC8mIrsQWFCSjDDIKIheJ5Mq/pJWWaUSSylteSzout5IsRNoH+VIv5yw5t0s55PyRN/7OXA9p08xtkZxnZPRUgtPnzZun2kU5z8n8e7kvMYrS0ZBzz41iIaQjIedJGYGQ96Rgum4pn4xWSNC4tBXS7srzS1nzxj9a0zZJWeX9ky/y8iVb0qhKmyexHNLuWlp/qTjJukGScljOv+YR6KVLl6qOVVEVd/ut9XvkcLROS0Wl79ixY6bhw4eb6tata/L09DR5eXmZGjZsaHr66adVWra8bpRuNm8qOXPq0cK2RYsW5abWe/755021atUyubm5mXx9fU2dO3c2/fLLL7dUdklrKCnfqlSposrdvn17lU5Q0tjJVjD14P/+97/c15KUdg899JDp+PHjucds2bJFpUGVVKV5U9cVTFeXl7ympdR1Zp9++qlKtSjp6eR9lXR8lp7v8OHDpg4dOqh6yO/MaVULS98nqVPl+aQukp5QPkN5P2+WLtZSesTCFPZ4Se0n6QC9vb1N5cuXNz311FOm/fv3W0w3KyliC7JUf0m9KOmJpU7y/ks6y549e5rCw8N1/R4RGZn5b0vSrRYkqZzr1KmjNvn7FXI+HTRokDq/yt9dtWrVTPfcc49KUVsw9Whh26ZNm9RxUVFR6rwqz+Hq6mry9/dXz7Vt27ZbKrv8rT/++OOmihUrqjTg3bt3V+cQ+bsumLb64sWLppEjR6rXkvNPUFCQOubChQu5x6xcudLUuHFjVZa857rCzhWSCjU4OFgd+/rrr1v8/ZtvvqkeK+2DpOFetWqVxeezpm3KyMgwTZkyJbetkzJMmDAhXxrgG6V8t9R+WlLY4+X/QJcuXVSd5Lw7ceJE07p16yymm73Vc29xt9+l9R6RyeQk/2jduSEiIiIiIvvGGAsiIiIiIrIZOxZERERERGQzdiyIiIiIiMhm7FgQEREREZHN2LEgIiIiIiKbsWNBREREREQ2c7gF8mQRLll0Rxa8sWZJeCIiI5PM44mJiWohQlko01GxjSAiKnr74HAdC2kwgoODtS4GEZEunTlzBkFBQXBUbCOIiIrePjhcx0KuQpnfHF9fX6sem5GRgbVr16Jbt25wc3ODvTJCPVgH/TBCPYxQB1vrkZCQoL5Qm8+RjsrR2wjWQT+MUA8j1MEo9cgopfbB4ToW5qFtaTCK0mh4e3urx9nrfyyj1IN10A8j1MMIdSiuejj69B9HbyNYB/0wQj2MUAej1COjlNoHx51IS0RERERExYYdCyIiIiIisu+Oxdy5c9G8efPcIee2bdvil19+ueFjli9fjoYNG8LT0xPNmjXD6tWrS628RERUOtg+EBHZH007FhJZ/tZbbyE8PBw7d+7EXXfdhfvvvx8HDhywePyWLVvQv39/DBkyBLt27UKfPn3Utn///lIvOxERlRy2D0RE9kfTjsW9996LXr16oV69eqhfvz7eeOMNlClTBtu2bbN4/AcffIAePXpg3LhxaNSoEaZOnYqQkBDMnj271MtOREQlh+0DEZH90U1WqKysLDWMnZSUpIa8Ldm6dSvGjBmTb1/37t3xww8/FPq8aWlpasubMsscHS+bNczHW/s4vTFCPVgH/TBCPQxRh6xsvLbqIOpnFa0eeq57SbUPRESOYtPRC/j9nBN6mkzG7ljs27dPNRSpqanqatSKFSvQuHFji8eeP38eAQEB+fbJfdlfmGnTpmHKlCnX7ZdcvpJ2qyjWrVsHIzBCPVgH/TBCPey5Dt+ccMZfMc6o4OECP/d1cLVyPDo5ORl6U9Ltg+DFp/xYB/0wQj2MUAcj1OP0pWSM/mYvElJdELYjEv9tXcOqx1tTb807Fg0aNMDu3bsRHx+Pb7/9FoMHD8aff/5ZaONhrQkTJuS7imVe5EMWCClKjnL54tG1a1e7zWNslHqwDvphhHrYex2++jsSf209DMkw/p+a2ejZ3fp6mL9Q60lJtw+CF58sYx30wwj1MEId7LUeaVnAjP0uSEh1Qo0yJnjHHsDq1ZZj1YrjwpPmHQt3d3fUrVtX3Q4NDcWOHTvUXNn58+dfd2xgYCBiYmLy7ZP7sr8wHh4eaitIGt2ifoGw5bF6YoR6sA76YYR62GMdNh2Nw+urj6jbY7vWQ/DVQ0Wqhx7rXdLtg+DFp/xYB/0wQj2MUAd7rofJZFIjFdHJMajg444n6ieX+IUnzTsWBWVnZ+cbls5LhsTXr1+P0aNH5+6TD7qwObdEREZ2Iu4qRiyOQFa2CQ+EVMOTd9bEL78cglGVRPvAi0+WsQ76YYR6GKEO9liPeX8ex+r9MXB1dsLs/i0Qe2BriV940rRjIVeKevbsierVqyMxMRFLlizBhg0b8Ouvv6rfDxo0CNWqVVND1WLUqFHo2LEj3nvvPfTu3RtLly5VaQgXLFigZTWIiEpdfHIGhn6xEwmpmQipXg5v/qcZnJANo2D7QERUdBv/icM7aw6r26/c1wRhNcrDyhlQRaJpxyI2NlY1DtHR0fDz81OLIUmjIUNNIjIyEs7O/0YgtmvXTjUukyZNwsSJE1UaQsn40bRpUw1rQURUujKzsjHy6wicuJCEqn6emD8wDJ5uLsjIME7Hgu0DEVHRRF5MxrNf70K2CegbGoQBbaojMzMTpUHTjsWnn356w9/L1amC+vbtqzYiIkf1+s+HVOpALzcXfDw4DJXKXj+Vx96xfSAisl5yeiaeXLQT8SkZaBFcDlP7NIWTk6T2cIAF8oiIyDpL/o7Ewi2n1O0Z/VqgSVU/rYtEREQ6CdZ+6bt9OHw+ERXLuGPegBA1ml2a2LEgIrITW49fxOSV+9XtsV3ro0fTKloXiYiIdOKTTSfx055zKlj7o0dDUcXPq9TLwI4FEZGdzJkdvjgcmdkm3NuiKkbelZOGlYiIaPPRC5h2LSvgy/c0Ruta/pqUgx0LIiKdS0zNwNAvd+BKcgaaB/lh+kPNS3XOLBER6deZS8kqoYcEaz8UGoRBba1bWbs4sWNBRKRjskbF6KW78U/MVQT4euDjQTkZoIiIiFLSs/DUovDcC0+vl3KwdkHsWBAR6dj0X49g/eFYeLg6Y8HAMAT4empdJCIi0kmw9vjv9+JgdIJaWXvegFDNLzyxY0FEpFPfR0SplVPFOw81V6kDiYiIxKebT2Ll7nNwcXbCnEdDULVc6QdrF8SOBRGRDu2KvIzx3+9Tt0d0roP7W1bTukhERKQTW45JsHbOytqTejfC7bUrQA/YsSAi0pno+BQ8uSgc6ZnZ6No4AGO7NtC6SEREpBNRlyVYe5eKwXsgpBoea1cTesGOBRGRjqRmZOHJL8MRl5iGhoFlMbNfSzg7MwMUERFBtRESrH0pKR1Nq/nizf8001WWQHYsiIh0FIg37tu92Hc2Hv4+7ioDlI+Hq9bFIiIinbQRE7/fhwPnElQboYdg7YLYsSAi0omPNhzPs2pqCIL9vbUuEhER6cTCLafw/a6zKlh79iOtEFRef20EOxZERDqw7mAM3l17RN2ecn8T3QTiERGR9raduIjXf85ZWXtir0ZoV6ci9IgdCyIijR05n4jRS3fBZIJaMfXRNtqtmkpERPpy9koKRiyOUMHafVpWxRPt9ROsXRA7FkREGrqclI6hX+5AUnoW2taugJfvaax1kYiISEfB2sO/CsfFpHQ0ruKLaQ8011WwdkHsWBARaSQjKxvPLI7AmUspCPb3UnEVbi48LRMREVSw9v9W7MfeqHiU93bD/IGh8HLXV7B2QWzBiIg08vqqg9h64iJ83F3wyaDbUN7HXesiERGRTny59TS+i4iCZByf/Yh9JPRgx4KISANfb4/EF1tPq9sz+rVEg8CyWheJiIh04u8TFzF11UF1e0LPRmhfV5/B2rrqWEybNg233XYbypYti8qVK6NPnz44ciQnK0phFi5cqOaW5d08PT1LrcxERLbaceoSJq/cr26/0K0+ujUJ1LpIRESkE9HxKRixJAKZ2Sbc16Iqht5ZC/ZC047Fn3/+iREjRmDbtm1Yt24dMjIy0K1bNyQlJd3wcb6+voiOjs7dTp/OuepHRGQP2T2eXhSOjCwTejevghGd62pdJCIi0lGw9tOLwnHhajoaVfHF2w/qO1hbVx2LNWvW4LHHHkOTJk3QokULNRoRGRmJ8PDwGz5O3uDAwMDcLSAgoNTKTERUVCnpWXhq0c7c7B7TH7KvBqM0cUSbiBwxWPvlH/ZjT1Q8/LzcMH+A/oO1dR1jER8fr376+/vf8LirV6+iRo0aCA4Oxv33348DBw6UUgmJiIreYLz03V7sP5sAfx93LBgUCm93V62LpVsc0SYiR/PV35FYHm4O1m6F6hX0H6xdkG5atezsbIwePRrt27dH06ZNCz2uQYMG+Oyzz9C8eXPVEXn33XfRrl071bkICgq67vi0tDS1mSUkJKif0kjJZg3z8dY+Tm+MUA/WQT+MUI/SqMOCTSfx455zcHV2wof9miOgjFuxv54t9dDb5ycj2gVHI2TkQka0O3TocNMRbSIie4u9m/JjzoXyl3o0xJ31KsEe6aZjIVem9u/fj82bN9/wuLZt26rNTDoVjRo1wvz58zF16lSLw+lTpky5bv/atWvh7V20nqBcPTMCI9SDddAPI9SjpOpw8LITFhyWAWIn9KmRiYuHtmH1IeiqHsnJydAza0e05WJVSEgI3nzzTTXdlohIr2ISUtWaRhKsLbF3T3aoDXuli47FyJEjsWrVKmzcuNHiqMONuLm5oVWrVjh27JjF30+YMAFjxozJN2IhU6hkSF2GzK29oicNdteuXdXr2isj1IN10A8j1KMk63DyQhImzf8bJmSiX1gQpt7XqMTiKmyph3k0V49KakRbcFQ7P9ZBP4xQDyPUoaTrkZaZrWLv4hLT0CCgDN64rxEyMzOL/XVKa0TbVes5x88++yxWrFiBDRs2oFYt69NpZWVlYd++fejVq5fF33t4eKitIGl0i/oFwpbH6okR6sE66IcR6lHcdUhMzcDwJbuRmJqJsBrlMbVPM7i7OuuyHnr+7EpqRFtwVNsy1kE/jFAPI9ShpOqx9Lgzdsc6w9vFhIerXsGf69eiJJX0iLar1o3FkiVLsHLlSpX54/z582q/n58fvLy81O1BgwahWrVq6uQvXnvtNdx+++2oW7curly5gunTp6vgvKFDh2pZFSKifLKzTXh+2W4cj0tCFT9PzB0QWiqdCqMpyRFtwVHt/FgH/TBCPYxQh5Ksx9IdUdi69SBkEHv2o6G4s17JLYJXWiPamnYs5s6dq3526tQp3/7PP/9cpaEVkn7W2fnfxvjy5csYNmyY6oSUL18eoaGh2LJlCxo3blzKpSciKtyM3/7Bb4di4eHqjPkDQ1Gp7PUjp6TtiLbgqLZlrIN+GKEeRqhDcdcj/PRlvPZzTrDduO4NcFfjKigNJT2irflUqJuRBiWvGTNmqI2ISK9+2ReNWb/nXCWf9kAzNA8qp3WR7A5HtInIyMHaw7/KWSi1V7NADO9YB0ahi+BtIiKjOHw+AWOX71G3h9xRCw+EWDd9h3JwRJuIjCg9M1t1KmIT01A/oAymP9TCUAulsmNBRFRMriSn48kvw5GcnoV2dSpgQs+GWhfJbnFEm4iMaMpPBxAReQW+nq5YMDAMPh7G+irOSEIiomKQlW3Cs1/vQuSlZASV98LsR0Lg6sJTLBER5Vi6PRKL/45Uwdof/LcValb0gdGw1SMiKgbTfz2CTUcvwNPNWV2F8vdx17pIRESkExGRlzF5Zc7K2i90a4DODSvDiNixICKy0aq95zDvz+PqtsyXbVzVujSlRERkXLGJOcHa6VnZ6NEkEM90Mk6wdkHsWBAR2eBQdALGLd+rbj/VsTbubVFV6yIREZGOgrVHLI5ATEIa6lUug3cfNlawdkHsWBAR2RCs/dSicKRkZKmFjV7szmBtIiL619RVB7Hj1GWU9XBVaxqVMViwdkHsWBARFTFY+7mlu1WwdrC/F2b1bwUXZ+NehSIiIut8s+MMFm07nROs3b8lalcqA6Njx4KIqAjeW3sEG/+JU8Ha8weEoZw3g7WJiCjH7jNXMOmH/er2813q466GAXAE7FgQERVhZe2PNuQEa7/9YHMGaxMRUa64xDQ8vSgnWLtb4wCM7FwXjoIdCyIiKxyNScQL11bWHnpHLdzfsprWRSIiIp3IyMoJ1j6fkIo6lXzw3sMt4OxA02TZsSAiukUJqRkqWDvp2sra47myNhER5fHGz4ew/dQlFaS9YFAYynq6wZGwY0FEdAuys00Ys2wPTlxIQrVyOcHaXFmbiIjMvg2PwsItp9TtGf1aoo4DBGsXxFaRiOgWzP7jGH47FAN3V2fMHRCCCmU8tC4SERHpxN6oK5i4Yp+6PbpLPXRt7BjB2gWxY0FEdBN/HI7FjN/+Ubdf79MUzYPKaV0kIiLSiQtXrwVrZ2ajS6PKeO6uenBU7FgQEd3A6YtJGLV0F0wm4NE21fFwWLDWRSIiIp0Fa5+LT0XtSj54v19LhwrWLogdCyKiQqSkZ+HpryKQkJqJVtXLYfK9jbUuEhER6cibqw/h75PXgrUHhsHXwYK1C2LHgojIApPJpObLHopOQMUy7pj7aCg8XF20LhYREenE9xFR+PyvnGBtSStbt7LjBWsXxI4FEZEFX249jRW7zsLF2QmzHwlBoJ+n1kUiIiKd2H82HhO+zwnWfu6uuujeJFDrIumCph2LadOm4bbbbkPZsmVRuXJl9OnTB0eOHLnp45YvX46GDRvC09MTzZo1w+rVq0ulvETkGMJPX8LUVQfV7Qk9G+L22hW0LhIREenExatpak2jtMxs3N2wMkZ3qa91kXRD047Fn3/+iREjRmDbtm1Yt24dMjIy0K1bNyQlJRX6mC1btqB///4YMmQIdu3apTojsu3fv79Uy05ExhSbmIpnFkcgM9uE3s2rYMgdtbQuEhER6URmVjZGLtmFs1dSUKsig7ULcoWG1qxZk+/+woUL1chFeHg4OnToYPExH3zwAXr06IFx48ap+1OnTlWdktmzZ2PevHmlUm4iMm52D2kwYhLSUK9yGbzzYHM4ObHBICKiHNN+OYytJy7Cx90F8weGws/LsYO1ddWxKCg+Pl799Pf3L/SYrVu3YsyYMfn2de/eHT/88IPF49PS0tRmlpCQoH7K6Ihs1jAfb+3j9MYI9WAd9MMI9TCX/Z01R7D95CX4eLhg1n9bwN3ZZFf1suWz0Fs9Zars999/j8OHD8PLywvt2rXD22+/jQYNGtx0quzLL7+MU6dOoV69euoxvXr1KrVyE5Fxrdx9Dp9uPpkbrF0/oKzWRdId3XQssrOzMXr0aLRv3x5NmzYt9Ljz588jICD/aoZyX/YX1jhNmTLluv1r166Ft7d3kcoqIyRGYIR6sA76Ye/12HXRCQv/OaNu96uRjiM7/sTNI76M81kkJydDT8xTZSUOLzMzExMnTlRTZQ8ePAgfH58bTpWV8/4999yDJUuWqKmyERERN2xXiIhuJioJ+HBlTuzdyM510aNpFa2LpEu66VhIAyJxEps3by7W550wYUK+EQ4ZsQgODlYNlK+vr9VX9KTB7tq1K9zc7Hfoywj1YB30wwj1OBJ9BS/O+1vdHnpHTbzUvb7DfRbm0Vy94FRZItKLS0np+PSIiwrW7tSgEp7vap9thMN0LEaOHIlVq1Zh48aNCAoKuuGxgYGBiImJybdP7st+Szw8PNRWkDS6Rf0SZMtj9cQI9WAd9MNe65GUlonRyw8gLdsJrWuWx/iejeDq4uxwn4XeP7uSmCpLRHQrwdrPf7MXl9KcUN3fCx/0a6XSkJMOOxayANWzzz6LFStWYMOGDahV6+bZV9q2bYv169eraVNmckVK9hMRWXsOGv/9PhyLS4KvmwkzH25u950KIyqpqbKCcXj5sQ76YYR6GKEOb605gi0nLqmYu1kPN4W3m33WJ6OUYvBctZ7+JHNgV65cqdayMJ/8/fz8VLCeGDRoEKpVq6bmzIpRo0ahY8eOeO+999C7d28sXboUO3fuxIIFC7SsChHZoS+2nMJPe87B1dkJj9fPRKWy149uknGnygrG4VnGOuiHEephr3WIuOCEL466qNuP1s3GqT1bcWoP7Nq6Eo7B07RjMXfuXPWzU6dO+fZ//vnneOyxx9TtyMhIODv/ewVRMoNIZ2TSpEkqmE+yfsgwNwPziMgaEZGX8cbqQ+r2i93rI+DKAa2LRKU8VVYwDi8/1kE/jFAPe67DoehEvPSxxN5lY2j76miWfcIu61HaMXiaT4W6GZkiVVDfvn3VRkRU1FVTRyyOQEaWCb2bVcFjbavjl1/YsdCT0poqyzg8y1gH/TBCPeytDpeT0jFi6W6kZmTjznoV8UK3Bvh1zQm7q4cWMXi6CN4mIiotWdkmjF62G9HxqahdyQdvPdgMXANPfzhVloi0CtZ+bukunLmUgur+3pjVn8Ha1mCUIhE5lA/WH8Wmoxfg5eaCeQNCUdbTvq8+GZVMlZVMUDJVtkqVKrnbsmXLco+RqbLR0dHXTZWVjkSLFi3w7bffcqosEVll+tojuW2ErKxdzttd6yLZlSKNWJw8eRKbNm3C6dOnVUBHpUqV0KpVKzXc7OnpWfylJCIqBhuOxGLW70fV7TcfaMpVU3WMU2WJqLSt2nsO8/88oW5P79scjapYF2dFVnYsFi9erBYgkqFlSeFXtWpVNSR96dIlHD9+XHUqHn30Ubz00kuoUaNGyZWaiMhKZ6+kqClQ8n310TbV8Z9WNw4EJiIix3EoOgHjlu9Vt5/qUBv3NK+qdZGM3bGQEQl3d3eVrem7775TWTPykjzgsjiRzGkNCwvDRx99xKtGRKQL6ZnZeGZxBK4kZ6B5kB8m39tY6yIZGke1icieXElOx1OLwpGSkaWCtV/s0VDrIhm/Y/HWW2+pFUwLI1k1ZC6sbG+88QZOnTpVXGUkIrLJm6sPYc+ZK/DzcsOcR0Lg4ZqTl5yKF0e1icgeE3o8t3Q3Ii8lI6i8Fz78L4O1S6VjcaNORUEVKlRQGxGR1n7eG42FW3IudLz/cAsE+xdt0TO6MY5qE5E9em/tEWz8Jw6ebs4qWLu8D4O1Sz0r1MKFCy3uz8zMVIsNERHpwYm4q3jpu5w5s8M71cHdjQK0LpJhyaj233//jWeeeea6TkXeUe158+bh8OHDqF27tiblJCIyW70vGh9tOK5uv/1gczSp6qd1kRyzY/Hcc8+pK02XL1/O3XfkyBG0adMGX3/9dXGWj4ioSFLSs1RcxdW0TLSu5Y+xXetrXSRDs3ZUOzQ0tETLQ0R0I0fOJ+KF5XvU7WF31sL9LatpXSTH7Vjs2rULUVFRaNasmVrVdM6cOQgJCUHDhg2xZ0/Oh0REpKVXftyPw+cTUbGMO2b3bwVXFy7bU1o4qk1EehafnIGnFu1EcnoW2tWpgJcYrF1sitTS1qlTB3/99RceeOAB9OjRA88//zw++eQTFbgnq6ISEWlp+c4z+GZnFCT+TgLxKvsyE1Fp4qg2Eek5WHvUsl04dTEZ1cp5YfYjIbzwVIyK/E7+/PPPKghP0geWK1cOn376Kc6dO1ecZSMiKtLw9ssr96vbz3epj3Z1K2pdJIfDUW0i0qsZ6/7BhiNx8HDNCdb2Z7C29h2Lp556Sl2NkpSBkqt87969KhuINCLffPNN8ZaQiOgWJaVlYvjicKRmZKND/UoY0bmu1kVySBzVJiI9WrM/GrP/OKZuv/VgMzStxvORLjoW0mBI9o+xY8fCyckJgYGBWL16NV577TU88cQTxV5IIqKbMZlMmLhiH07EJSHQ1xMz+7WEM3ORa4aj2kSkJ0djEjH2m5wR0yfa18J/WgVpXSRDKlLHIjw8HC1atLhu/4gRI9TviIhK29fbz2Dl7nNqYaPZj7Ti8LaGOKpNRHoSn5KBJxeFIyk9C7fX9seEXgzW1nyBvIL5yAvToEEDW8pDRGS1/Wfj8epPB9TtF7s3QFhNf62L5NDMo9rmC1DmUW2JtZBR7YcffljrIhKRg8jONuH5Zbtx8kISqvp5Ys4jIXBjsHaJueV3VubJbtu27abHJSYm4u2331YNCBFRSUtMzcDIJRFIz8zG3Q0rY9idXHhNaxzVJiK9mLn+KH4/HHstWDsMFcoUfnGcSnHEQoa1H3zwQRV4d++99yIsLAxVq1aFp6enSil48OBBbN68WV2V6t27N6ZPn14MxSMiunFcxfjv9+WmDXzv4RaMq9ABjmoTkR78euA8Plx/VN1+8z/N0CyIwdq6GbEYMmQITpw4gYkTJ6pOxJNPPok777wTt912m1px9eOPP0b16tWxY8cOLFu2TN2+mY0bN6pOinRQJAj8hx9+uOHxGzZsUMcV3M6fP3+r1SAiA/lq22n8vDcars5OmPVIK5TzZlyFVjiqTUR6ciz232Dtx9rVxIOhDNbWXYyFXIUaMGCA2kR8fDxSUlJQoUIFuLm5Wf3iSUlJarhc5txKWsJbJQst+fr65t6vXLmy1a9NRPZtX1Q8pq46pG6P79kQIdXLa10kh8ZRbSLSi4TUnGDtq2mZaFPLH//r3UjrIjmMIgVvm0kDYktO8p49e6rNWtKRkPSFROS4jcYIiavIykbXxgEYckctrYvk8GRUWy46LV++XI1aL1iwQF18EjKy3LhxYzW6LaPajRqxkSeikgvWHrNst0o9XkWCtR9lsLZuOxYffvihxf3Suahfv77KV14aWrZsibS0NDRt2hSvvvoq2rdvX+ixcpxsZgkJCepnRkaG2qxhPt7ax+mNEerBOjhuPSSu4sXlexF5SeIqPDGtT2NkZmba9Jz8LIqn7sU9qk1EZK0Pfz+K3w7Fwt3VGfMGhKIig7X127GYMWOGxf1XrlxRDUi7du3w448/wt+/ZFI9VqlSBfPmzVND7NJZkJVcO3XqpNIahoSEWHzMtGnTMGXKlOv2r127Ft7e3kUqx7p162AERqgH6+B49dh03glrTrrAxcmEfkFX8dcfxfe6jvxZJCcnF3s5bB3VJiKyxrqDMZj5W06w9ht9mqJFMGe36LpjcfLkyUJ/J4HdcpVq0qRJ+Oijj1ASJJtI3owi0pE5fvy46vAsWrTI4mMmTJiAMWPG5BuxCA4ORrdu3fLFadzqFT1psLt27WrXV9+MUA/WwTHrceBcAl5Y8LeMW+ClHg3xeLsaxfK8/Cz+Hc21RXGPakuCD4nFkBS10dHRWLFiBfr06XPDBB+dO3e+br88VtbSICLjOh53VU2BEoPb1kDfsGCti+SQbIqxyKt27dp46623VCB2aWrdurUKCLzR0Lyl1IfS6Bb1C4Qtj9UTI9SDdXCcekhcxahv9iIjy4QujQIwrEMdNXe/ODnyZ1Ec9S7uUW0m+CCiW13P6MkvdyIxLROta/pj0j2NtS6Swyq2joWQFLOlnfp19+7daooUERmXxFVM+G4fTl9br+Ldvs2LvVNBtivuUW0m+CCiWwnWlrSyx+OSEOjridmPtmKwtlE6Fvv27UONGrc+NeHq1as4duxYvkZJOgpyNUs6KTKN6ezZs/jyyy/V72fOnIlatWqhSZMmSE1NVTEWv//+u4qXICLj+urvSPy8L2e9itlcr8IuleaotjUJPojIvs354xjWHoyBu4sz5g0MReWynloXyaG5FsccXBniljmwY8eOxeDBg2/5+Xbu3JlvPqw5FkKeY+HChWpebGRkZO7v09PT1WtIZ0MCr5s3b47ffvvN4pxaIjKG/WfjMfWng+q2xFW04noVdqukR7WLkuCDmQPzYx30wwj1KOk6/HEkDu//9o+6/eq9jdAk0KdEXsvRP4sMKx5jVcdChpYLm34g+4cOHYrx48ff8vPJCV+mOBRGOhd5vfjii2ojIseZNzvy2noVdzesjKF3cr0Ke2btqHZpJPhg5kDLWAf9MEI9SqIOsSnA+/tcYDI5oX1ANnxi9mD16pyVtkuKo34WyVZkDbSqY/HHH39Y3C9BcvXq1VMrrMbGxqrVVomIbCEXHSau2I9TF5NR1c8T7/ZtwbgKnSvuUe3SSPDBzIH5sQ76YYR6lFQdZEXtvvP/RkpWEkKrl8OCx8PUuhUlxdE/iwQrsgZa1bHo2LHjDX+/Z88eNdyclZVlzdMSEV3n6+1n8NOec3BxdsKsR1qhvA/jKvSuuEe1SyPBBzMHWsY66IcR6lGcdVDJPJbuxbG4JAT4emDuwFD4eJXOIniO+lm4WXF8sQZvExEVh0PRCZjy0wF1e1z3BgitUTKLblLxKu5RbSb4IKKCPtpwHGsOnIebixPmDmCwtt6wY0FEupKUlokRSyKQlpmNTg0q4ck7a2tdJNJoVJsJPogorz+OxOLdtUfU7Sn3NUUIk3noDjsWRKQbMsQ96Yf9OHEtH/n7D7eEszPjKhwVE3wQkdmpC0kY9fUuyCmhf+vqeKRNda2LRLZ2LPbu3XvT1U6JiIpq+c4orNh1VsVVfNi/FfwZV0FE5PBkJPupReFISM1Eq+rl8Op9XFnbEB0LWXRIAvAsXUEy72fWFiIqin9iEjH5x/3q9piu9dG6FuMqiIgcnXy3fPHbvTgSk4hKZT0wb0AoPFxdtC4WFUfHQgLniIiKW3J6JkYsjkBqRjburFcRwzvW0bpIVAQc1Sai4jbvzxP4eV90TrD2oyEI8GWwtmE6FiW5sBEROa5XVh7A0dirqFzWAzP6Ma7CXnFUm4iK05//xOGdXw+r26/c2wRhNTmSbaiOxTvvvINnn30WXl5e6v5ff/2FsLCw3BzgiYmJeOmll/DRRx+VTGmJyHC+C4/C8vAoSF/ig/+2QsUypZOPnIofR7WJqLicvpiE564Fa/cLC8ajDNY2XsdCcoY/9thjuR2Lnj17qpzitWvXzl3ye/78+exYENEtORabqLJAidFd6qNtnQpaF4lswFFtIiqu6bESrB2fkoGWweXwWp8mHO20E1atf15wePtGaQCJiG4kJT0LIxbvQkpGFtrXrYARnetqXSQqRps2bcKAAQPQtm1bta6EWLRoETZv3qx10YjIDoK1D59PVCPYcweEMFjbqB0LIqLi8uqPB1SWD2k4ZvZrpVLMkjF899136N69uxrd3rVrF9LS0tT++Ph4vPnmm1oXj4h07ONNJ7BqbzRcnWVl7RBU8cuZJUP2gR0LIip130dEYdnOM5CR7Q//21KlECTjeP311zFv3jx8/PHHcHNzy93fvn17REREaFo2ItKvzUcv4K1fzMHajXEbg7WNv/L2J598gjJlyqjbmZmZauXTihUr5gZvExHdLK7ifyty4ipG3V0P7ermnD/IOCStbIcOHa7b7+fnhytXrmhSJiLStzOXkjHy6whkm4CHw4Iw4HbGbBm+Y1G9enV1BcosMDBQzZkteAwR0c3iKtrVqYBn76qndZGoBEjbcOzYMdSsWTPffomvMCf7ICLK2zY8uSgcV5Iz0CLID6/d35TB2o7QsTh16lTJlYSIDO+VH/f/G1fx35aMqzCoYcOGYdSoUfjss8/Ul4Nz585h69atGDt2LCZPnqx18YhIZ8HaL323F4eiE1CxjDvmDQyFpxuDtR2iY5GamorffvsN99xzT276WXNQnnoyV1e89tpr8PTkqohEdP16Fd/szFmvQuIqKpflecKoxo8fj+zsbNx9990qDblMi5L1jsaNG4ehQ4dqXTwi0pFPN5/Ej3vOqWDtOY8wWNuhgrclnkLWqTCbPXs2tmzZorJ+yCbToqxZw2Ljxo249957UbVqVXVV64cffrjpYzZs2ICQkBDVSNWtW1eViYj07WjMv+tVjLq7PuMqDE7O5//73/9w6dIl7N+/H9u2bUNcXJyKsahVq5bWxSMindhy7ALeXH1I3Z7UuxHa1OZaRg7VsVi8eDGefPLJfPuWLFmCP/74Q23Tp0/H8uXLb/n5kpKS0KJFC8yZM+eWV3Xt3bs3OnfurBbmGz16tLr69euvv1pTDSIq5YWOnlkcoeIq7qhbESPv4noVRiUj2DKSHRYWpjJArV69Go0bN8aBAwfQoEEDfPDBB3j++ee1LiYR6SRYe8SSnGDtB0OCMLhd/pgscoCpUBKM16xZs9z7MuXJ2fnfvknr1q0xYsSIW34+Wblbtlsl6Qvlatd7772n7jdq1EgFA86YMUPlTCci/c2dlZGKo7FXVUrZGf0YV2FkEj8ho9pdunRRo9l9+/bF448/rkYs5Lwt911cOHeayNFJsLasrH05OQPNg/zwxn8YrO2QHQtJE5g3pkKGtvOSObV5f1/cJPhPGqy8pEMhIxdEpD/Ld0bh+4izKq5iVv9WXK/C4GTE+ssvv8R9992npkA1b95cpSXfs2cPvzQQUe4Fp4kr9uFgdAIq+Lhj3gAGaztsxyIoKEg1FjKkbcnevXvVMSXl/PnzCAgIyLdP7ickJCAlJUWt8lqQdHTydnbkWJGRkaE2a5iPt/ZxemOEerAO+q/H4fOJeHllTlzF83fXRWiwr27ravTPwprH2iIqKgqhoaHqdtOmTVUsnEx9YqeCiMw+++sUVuw6q0avZz8SgqrlGKztsB2LXr16qaFuiXMomPlJvthPmTJF/U5Ppk2bpspV0Nq1a+Ht7V2k51y3bh2MwAj1YB30WY/ULOC9vS5Iy3RCo3LZCLp6GKtX56ymqmdG/CxulWRvslVWVhbc3d3zZQo0L6hKRLTleP5g7bZ1GKzt0B2LiRMn4ptvvlEjFiNHjkT9+vVzV1mVDFEy5C3HlOSiSzExMfn2yX1fX1+LoxVCAgnHjBmTb8QiODgY3bp1U4+z9oqeNNhdu3aFm5sb7JUR6sE66LceMsw9+pu9iE2NQaCvB74Y3hblvf/9sqlHRv0srGEezbWFfPaPPfaYGqkwpyh/+umn4ePjk++477//3ubXIiL7cvZKCkYu2YWsbBMeaFUNjzFY25Cs6ljItCMJyBs+fLjKUy6NiJBhbmnIJNVswalKxalt27Yqy0he0ojK/sJIA2du5PKSRreoXyBseayeGKEerIP+6rHwr5NYvT9G5ST/aEAoKvvl/1KpZ0b7LKx9jK0GDx6c7/6AAQNsej5JSS7ZBsPDwxEdHY0VK1agT58+N01JLheTJBOVXESaNGmS6uwQkXZSMyRYeycuJaWjaTVfvPlAM06RNCirOhZCsjKtWbNG5SeXLFFC1pPw9/e3+sWvXr2a+xzmdLKSRlaeq3r16mq04ezZsyoYUMiVLxkZefHFF/HEE0/g999/VyMoP//8s9WvTUTFLyLyMt64Nsw9sVcjhFQvr3WRqBR9/vnnxfp85pTkcr5/4IEHbjklubQVkh59/fr1KiV5lSpVmDmQSCNyDXryjwex/2wC/BmsbXhWdyzM5Mu/pJe1xc6dO9WaFGbmKUty1UsWvpMrVJGRkfk6NdKJkGBAyYcugeKffPIJGwwiHZArUSMXRyAjy4RezQLxeHsOc5NtmJKcyP5tOu+EFaeirwVrt0JQ+aLFt5LBOxbFoVOnTrnTqSyxtKq2PEZW+SYi/ZAFjsZ+uw/n4lNRq6IP3n6wOYe5qdQVJSU5MwfmxzrohxHqseVoLFacylnv7KXu9XFbdT+7rI8RPouMUsoaqGnHgoiM4dcoZ2yOughPN2fMHRCCsp72H6dA9qcoKcmZOdAy1kE/7LUel9OAd/e6IBtOCK2YjcqXD2D16gOwZ/b6WZRm1kB2LIjIJhuPXsCvUTmjE9MeaIaGgdZlWyPSEjMH5sc66Ic91yMtIwv9P92Bq5kJqOZtwoJhneDrnX+ZAntiz59FaWcNZMeCiIos6nIyxi7fBxOc8EjrIPynVcktkElUEinJmTnQMtZBP+ytHmpl7R8OYt/ZBJTzcsOQBimqU2FPdTDKZ6FF1sCciW9EREVIHzj8qwhcSclAdR8TJvZsqHWRyMFJ6nHJBGVNSnIiKl5fbTuN5eFRcHYCZvZrjgr2O1BBRcCOBREV6YrU5JX7se9sPMp7u+HxBlnwcOXphIqXpCSXFOSy5U1Jbs4WKNOYBg0alHu8pJk9ceKESkl++PBhtbaSpCSXTIJEVPK2n7yEKT8dVLfH92yI9lxZ2+HwmwARWW3pjjP4Zue1K1IPN4f/9TNJiGwmKclbtWqlNiGxEHJ78uTJ6n5hKclllELWv5C0s0xJTlQ6ouNT8MzicGRmm3BP8yoYdmdtrYtEGmCMBRFZZVfkZbyyMiezxwvdG6BdnQpYfUTrUpERMSU5kf1MjX36qwhcuJqOhoFl8c5DTDnuqDhiQUS3LDYxVcVVpGdlo3uTAAzvWEfrIhERkYak8y8Xm/acuQI/LzcsGBgGb3det3ZU7FgQ0S1Jz8zGiMUROJ+QijqVfPBu3xa8IkVE5OAW/x2JZTvPqKmxs/q3QvUKXFnbkbFjQUS35I2fD2LHqcso4+GKBYPCuAgeEZGD23lKgrVzpsa+2KMhOtSvpHWRSGPsWBDRTX2z8wy+2Hpa3Z7RryXqVCqjdZGIiEhD5+NTVVxFRpYJvZtVwVMdGKxN7FgQ0U1ERF7GpBX71e1Rd9dD18YBWheJiIg0lJaZheGLw3HhahoaBDBYm/7FjgURFSomIRVPLwpXwdrdGgeojgURETm2V388gF2RV+Dr6Yr5A0Ph48FgbcrBjgURFZo+8MlF4YhNTEP9gDJ4v19LOEt0HhEROawlf0fi6+1nIAMUH/ZvhZoVfbQuEukIOxZEZDF94ITv9+WmD/x4UJgK2iYiIscVfvoyXvkxZ2rsC90aoFODyloXiXSGHQsius7cP49jxa6zcHF2wkePhqBGBV6RIiJy9Kmxw78KV8HaPZsG4plOXMeIrseOBRHls/bAeUz/NWcp7VfvbYz2dStqXSQiItJ4HSPpVMjU2HqVy2A61zGiQrBjQUS5Dp5LwOhlu2EyAQNur46BbWtqXSQiItKYrFUREXkFZT1z1jHi1FgqDDsWRJQ7zD3kix1ITs9CuzoV8Mq9TbQuEhERaWzp9ki1urYK1v5vK9RisDbpvWMxZ84c1KxZE56enmjTpg22b99e6LELFy5Uw295N3kcERVdcnomhn6xE9HxqahTyQdzHw2Fm4suTg9ERKThOkaTV+asrD2mS310bshgbboxzb85LFu2DGPGjMErr7yCiIgItGjRAt27d0dsbGyhj/H19UV0dHTudvp0zorARGS97GwTnl+2G/vOxsPfxx2fPXYb/LzdtC4WERFpKDYxJ1hb1jHq3iQAIzrX1bpIZAc071i8//77GDZsGB5//HE0btwY8+bNg7e3Nz777LNCHyOjFIGBgblbQABXAiYqqjdWH8KvB2Lg7uKMBQNDmQGKiMjBSbD2iMURiElIQ93KZfDew1zHiG6NptE36enpCA8Px4QJE3L3OTs7o0uXLti6dWuhj7t69Spq1KiB7OxshISE4M0330STJpbng6elpanNLCEhQf3MyMhQmzXMx1v7OL0xQj1Yh+KxcOtpfLr5pLr91gNN0KJaWYf8uzBCHWyth73XnYiKz9RVB7Hj1GWU9XBVF5wYrE23StP/KRcuXEBWVtZ1Iw5y//DhwxYf06BBAzWa0bx5c8THx+Pdd99Fu3btcODAAQQFBV13/LRp0zBlypTr9q9du1aNjBTFunXrYARGqAfrUHR7Ljrh839k0NIJ91XPgkvULqyO2lXk5+NnYd/1SE5OLpGyEJF9+WbHGSzaljPFfEa/lqhdqYzWRSI7Yndd0LZt26rNTDoVjRo1wvz58zF16tTrjpfREInhyDtiERwcjG7duqlYDWuv6EmD3bVrV7i52e8cdCPUg3Wwzc7Tl7F4YThMyMYjrYPw6j2NipyTnJ+FMephHs0lIse1+8wVTPohZ2Xt57vUR5fGnGpOdtSxqFixIlxcXBATE5Nvv9yX2IlbIY1nq1atcOzYMYu/9/DwUJulxxX1C4Qtj9UTI9SDdbDekfOJeOqrXUjLzEaXRpXx2v3N4FoMGaD4Wdh3PYxQbyIqurjENDy9KCdYu2vjADx7F4O1yc6Ct93d3REaGor169fn7pO4Cbmfd1TiRmQq1b59+1ClSpUSLCmRMURdTsagz/5GQmomQmuUx6z+IcXSqSAiIvuVkZWNEUsicD4hFbUr+eD9h1swWJuKRPNvFDJN6eOPP8YXX3yBQ4cOYfjw4UhKSlJZosSgQYPyBXe/9tprKj7ixIkTKj3tgAEDVLrZoUOHalgLIv27eDUNgz7brrJ81KtcBp8ODoOXu4vWxSK6Ia5zRFTy3vj5ELafvKSCtBcMDENZT45gkp3GWPTr1w9xcXGYPHkyzp8/j5YtW2LNmjW5Ad2RkZEqU5TZ5cuXVXpaObZ8+fJqxGPLli0qVS0RWZaQmqE6FSfiklDVzxNfDmmNct7uWheL6JbWOZI05NKpmDlzplrn6MiRI6hc2fJCXRI7J783K2rsEJGj+DY8Cgu3nMoN1pb0skR227EQI0eOVJslGzZsyHd/xowZaiOiW5OSnoUhC3fgwLkEVPBxx6KhbVDFz0vrYhFZtc6RkA7Gzz//rDIDjh8//obrHBHRze2LisfEFfvU7VF311OxFUR237EgopKRlpmFp74Kz8lH7umqRirqMHUg2YHSWOdIcK2j/FgHx6nHxaR0PLlop1oM764GlfBMh5rF/lr8LBxvnSN2LIgMShqLZ76KwMZ/4uDl5oKFj9+GJlX9tC4WkW7WORJc68gy1sHY9cjKBj465IzoBGdU9jShm2801qyJRknhZ+E46xyxY0Fk0AwfI5dEYP3hWHi4OqtA7dAa/loXi0hX6xwJrnWUH+vgGPV4Y/VhHEuIhI+7C74Y1qbE4ir4WTjeOkfsWBAZsFMxaukurD0YA3dXZ3w8KAzt6lbUulhEulvnSHCtI8tYB+PWY8WuKCzcGqluv/dwSzSqVh4ljZ+F46xzpHm6WSIq3ulPMlKxet95uLs4Y/7AUHSoX0nrYhFZjescERW//WfjMf67nGDtkZ3rokdTJjqg4sURCyKDSM3IwjOLI/D74Vg1UjFvQAg6N7CckpPIHsgUpcGDByMsLAytW7dW6WYLrnNUrVo1FSdhXufo9ttvR926dXHlyhVMnz6d6xwRXXMpKR1PLQpHWmY2OjeohOe71te6SGRA7FgQGUByeqZqMDYdvQBPN2e1wBFHKsjecZ0jouKReS3u7uyVFNSs4I2Z/20FF66sTSWAHQsiO3clOR1PLNyBiMgr8HZ3waeDb0PbOhW0LhZRseA6R0S2e+uXw9hy/KJqIxYMCoOfl33HCZB+sWNBZMdiElIx6NPtOBKTCF9PV3z++G3M/kRERLlW7j6LTzafVLff7dsC9QPKal0kMjB2LIjs1PG4q3js8+04cykFlct6YNGQNmgQyAaDiIhyHDgXj5e+26tuP9OpDno1YyIDKlnsWBDZoR2nLmHYlztxJTkDNSp446shbRDsX7TFvIiIyHguXwvWTs3IRsf6lTC2WwOti0QOgB0LIjuzau85jPlmj0ot2zK4HD4ZHIaKZa7Pw09ERI4brP3s17sQdTkF1f298SGDtamUsGNBZCeys034YP1RtYnuTQIws18reLm7aF00IiLSkem/HsHmYxfg5SbB2qHw82awNpUOdiyI7EBSWibGfrMHaw6cV/efaF8L/+vdiFegiIgonx/3nMP8jSfU7el9m6NhoK/WRSIHwo4Fkc6dupCEp78Kx+HziXBzccIbfZrh4duCtS4WERHpzKHoBLz47R51++mOdXBP86paF4kcDDsWRDq2Zn80xi3fi8S0TBVHMX9gCNPJEhGRxTWNnly0UwVr31mvIsZ1Z7A2lT52LIh0KC0zC++sOYJPr+Uev61meczqH4JAP0+ti0ZERDqTlW1SwdqSfjzY34vB2qQZdiyIdOZYbCKe+3o3DkYnqPtPdqitrjy5uThrXTQiItJpsPamo9eCtQeGobyPu9ZFIgeli28qc+bMQc2aNeHp6Yk2bdpg+/btNzx++fLlaNiwoTq+WbNmWL16damVlagksz59ufUUen+4WXUqynu7YcHAUEzs1YidCiIisujnvdGY9+dxdfvth5qjURUGa5N2NP+2smzZMowZMwavvPIKIiIi0KJFC3Tv3h2xsbEWj9+yZQv69++PIUOGYNeuXejTp4/a9u/fX+plJyrOAO3+H2/D5JUHkJaZMz/219Ed0K1JoNZFIyIinTp8PgEvLN+TO7p9XwsGa5ODdyzef/99DBs2DI8//jgaN26MefPmwdvbG5999pnF4z/44AP06NED48aNQ6NGjTB16lSEhIRg9uzZpV52IltlZQOfbD6FHh9sxN8nL6lh7FfubYwvHm+Nyr6MpyAiIsvikzPUytopGVm4o25FvMhgbXL0GIv09HSEh4djwoQJufucnZ3RpUsXbN261eJjZL+McOQlIxw//PCDxePT0tLUZpaQkDNvPSMjQ23W+C78DPbFOiE14gw83NxUYJSrbC5O6ra7i7O6L9NWcjYnuLk6q/3urs7wuLbJMU5O2gVVmettbf31xAh12PRPLN7Z64LzKf+o++1q+2Pq/Y3VKqlZWZnIyoJdMMJnYYQ62FoPe687kaMFaz+3dBdOX0xGUHkvzOrfCq6cMkuO3rG4cOECsrKyEBAQkG+/3D98+LDFx5w/f97i8bLfkmnTpmHKlCnX7V+7dq0aGbHGlO0uSMlyweLjh2ALJ5jg5ozczV02l2s/nU3wcEHO5gx4uAKeLiZ4ushPwEs2V5P66e0qt3MeV5R+yrp162Dv7LEOcSnAqjPO2H1RGgEn+LiacF+NbLSpFIv922Jhr5P67PGzMGIdilqP5OTkEikLERW/99cdwZ//xMHTzRnzB4YyWJt0w/BZoWQ0JO8Ih4xYBAcHo1u3bvD1tS7AaXX8LkSei0G58hVgApCZbVKbXDnIyDIhMytb/czIylb75Wd6ZjbSr+03M8EJ6dlQ2/Ws7yHIaEg5Lze1lfdxg7+3O/x93FHBxx3+ZdxR0ccdlcp6oGIZd1Qu6wEXZKsvHl27doWbmxvskVxdtbc6XLiahtl/nMCyvVHq/4dkAmwfkI13BnZARV/rOrl6Yo+fhRHrYGs9zKO5RKRvv+yLxpw/rgVrP9gcTar6aV0kIn10LCpWrAgXFxfExMTk2y/3AwMtB63KfmuO9/DwUFtB0uha2/DO7t9KZaDq1es2qx8rGX+kg5GWka3WKJAFbFLVzyykpGchOSMLqelZSEqX+5nqZ1JaJq6mZaqfianmLUP9jE/JUJt8QZXOS2ximtpuha+nK7ydXLA8bi+qlvNCoJ8Xqvp5qtuyVSvnBS8ZQrEDRfkcS1t0fAo+3ngSX2+PVHNhRcf6lTC2S12c3LVJdSr0XgejfBaOUIei1sMI9SYyun9iEjH2WrD20Dtq4f6W1bQuEpF+Ohbu7u4IDQ3F+vXrVWYnkZ2dre6PHDnS4mPatm2rfj969OjcfXKFTvbrmbOzEzydXeDpJl/Yi6cBN5lMSE7PwuXkdFxJzlA/LyX9u124KlsaLl5NQ9zVNMQmpKmMQwmpmUiAE84fu1joc8voRrXy3mrupsz5Dy7vrX7WqOCtOh9ceOfmDkUnYOFfp/D9rqjcEauWweXwUo+GaFungrq6fHKX1qUkIiJ7IBcTn/xyp2r329WpgPE9G2pdJCL9TYWSaUqDBw9GWFgYWrdujZkzZyIpKUlliRKDBg1CtWrVVKyEGDVqFDp27Ij33nsPvXv3xtKlS7Fz504sWLAAjkYCwH08XNUWVP7WOiKJaZk4e/EqfvptE2o0ao64qxk4F5+K8/GpOHclBWcvp6hjcjol6dhz5sp1zyNB6dLRkE5GzYo+qJVnq+rnpTpRjkpGoNYdjMGibaex/eSl3P1tavlj5F11VeYOLQP3iYjI/siU69FLd+HUxWQ1q2D2IyEM1iZd0rxj0a9fP8TFxWHy5MkqALtly5ZYs2ZNboB2ZGSkyhRl1q5dOyxZsgSTJk3CxIkTUa9ePZURqmnTphrWwj7IF1pfTzd4VS6DBuVM6NWqmsXpD3JVJOpyMs5cSrn2MxmnLyUj8lIyoi6lqCldJy4kqQ1H4q6L96hVwQe1K13bKpZBncpl1G15baOe8CMiL2PFrrNYteecGhESMqrTo0kgnrijJkJr+GtdTCIislMzf/sHfxyJU5klJVhb4iiJ9EjzjoWQaU+FTX3asGHDdfv69u2rNioZfl5u8PPysxgQJl+izyek4vSFJJy8mKQWdjt5IRknL1xVHQ+J9zgSk6i2giqW8VAdjDrXOhwywiH3g/297W5laYl7+fvkRTU6se5grJpyZlbFzxMPhQbh0TY1EOjHtSiIbDFnzhxMnz5dXXiSBVRnzZqlRrcLs3z5crz88ss4deqUuvD09ttvo1evXqVaZqLitPZgDGb9fkzdfuvBZmhajcHapF+66FiQ/ZCr8DIMK1u7uhXz/U6yYp29koITcUk4Hnc1Z1RDfsYlqcBy+fItW94pQubnDC7vpaZV1azgo6ZYyVbd30fFeOTEpWhLYlZ2n7mMXZFXsO3ERfVTAufNynq6omvjADwUEoTba1dw6OlgRMVl2bJlarqsLJzapk0bNVVW1i06cuQIKleufN3xW7ZsQf/+/dXU2XvuuUeNbkv8XkREBEe1yS6dTQLmfJeThPyJ9rXwn1ZBWheJ6IbYsaBiI/M9a6iOgQ86N8zf6Es2q5Oqo3Gts3HttuyTTEkyb1Q2IP/UKiEpcquVz+nMqCxWvp6o6OOKEwlQiwMFlveBj7uLzbELkh5YYk3OXE5G1OUU1Tk6GnNVZeGQ+wVJMHuH+hXRvUkg2tSqoKaBEVHxef/99zFs2LDcmDvpYPz888/47LPPMH78+OuO/+CDD9CjRw+MGzdO3Z86dapK7jF79mz1WCJ7Idkj5/x+HHP2uSDLlIXba/tjYi8Ga5P+sWNBpaKspxuaB5VTW8GA8piENJy4cFV1Ek5dm14VeSkFkReTVNpdcypdGSXIzxUfHNisbsmXer9ra3nI6IG3u2wu8HBzUSudm7NYSdrfLJNJBVlLZg2Z0nQlJQMXr6ar2JIbkSlcLYPLI6xmebSvUxHVK9jv2hNEepeeno7w8HC1FpGZxNt16dIFW7dutfgY2Z933SIhIxwSh1eYtLQ0tRVcz0OytlmzGvnmYxexau85nD3rjI3f78sXG2hPJDMj66C98NOXceKCXGxzwh11/PFe3+YwZWchIzsnZbm9MP8NWfO3pEdGqEeGDXWw5jHsWJCmZJRB4hBka1cH13U6ZArS2WvZquTnuSupiElIVWtDnI65jORsF6Rk5CxEGJeYpjZbSAclSKZ6ydSsCj6oH1AG9QLKolGgL/y8jRl8TqRHFy5cQFZWVm4iDzO5f/jwYYuPkTgMS8fL/sLItKkpU6Zct3/t2rXw9r71iwcbop2w4pRM23QGYqNh31gHPSjrZsIDNbPRqkIstv35G+yZjBwagRHqsa4IdUhOlk7urWHHgnTd6ahQxkNtBUc6pPecs1hhd6RnO6k1PNSigckZKl2uLDqYlJ6pOhzmldGFxIg7OzmpuA0fDxc1siHZqiqVlZXKPdSoB+MjiByHjIjkHeWQEYvg4GB069YNvr6+t/w8QVHxqHE0DseOHUXduvXgYqdXyrOys1kHHZA08j0bV8T2zRvQtWtXu13AUtpq+SJrz3UwSj0ybKiDeST3VrBjQXbPmrU8iMg+VKxYES4uLoiJicm3X+4HBgZafIzst+Z44eHhoTZbVy8PrVURzYP8sDrlH/TqXNeuv3ywDvpgnn5i7f9FPTJCHYxSD7ci1MGa4+2zK09ERIbm7u6O0NBQrF+/Pt/cebnftm1bi4+R/XmPF3KFrrDjiYioeHHEgoiIdEmmKA0ePBhhYWFq7QpJN5uUlJSbJWrQoEGoVq2aipMQo0aNQseOHfHee++hd+/eWLp0KXbu3IkFCxZoXBMiIsfAjgUREelSv379EBcXh8mTJ6sA7JYtW2LNmjW5AdqRkZH5sv60a9dOrV0xadIkTJw4US2QJxmhuIYFEVHpYMeCiIh0a+TIkWqzZMOGDdft69u3r9qIiKj0McaCiIiIiIhsxo4FERERERHZzOGmQsmia9bm5M2b+k0WCZHH2nO6MSPUg3XQDyPUwwh1sLUe5nOi+RzpqBy9jWAd9MMI9TBCHYxSj4xSah8crmORmJiofsoCSEREdP050s/PD46KbQQRUdHbByeTg12ekjzo586dQ9myZdXKztYwr8h65swZq1Zk1Rsj1IN10A8j1MMIdbC1HtIUSKNRtWrVfJmWHI2jtxGsg34YoR5GqINR6pFQSu2Dw41YyBsSFBRk03PIB2Kv/7GMVg/WQT+MUA8j1MGWejjySIUZ24gcrIN+GKEeRqiDUerhW8Ltg+NeliIiIiIiomLDjgUREREREdmMHQsreHh44JVXXlE/7ZkR6sE66IcR6mGEOhipHvbKCO8/66AfRqiHEepglHp4lFIdHC54m4iIiIiIih9HLIiIiIiIyGbsWBARERERkc3YsSAiIiIiIpuxY1FE9913H6pXrw5PT09UqVIFAwcOVIsq2ZNTp05hyJAhqFWrFry8vFCnTh0V2JOeng578sYbb6Bdu3bw9vZGuXLlYC/mzJmDmjVrqv9Dbdq0wfbt22FPNm7ciHvvvVctmCMLif3www+wN9OmTcNtt92mFkOrXLky+vTpgyNHjsCezJ07F82bN8/NTd62bVv88ssvWhfL4dl7G2GU9sFe2wi2D9ozQvugRRvBjkURde7cGd988436T/bdd9/h+PHjeOihh2BPDh8+rFaZnT9/Pg4cOIAZM2Zg3rx5mDhxIuyJNHR9+/bF8OHDYS+WLVuGMWPGqIY6IiICLVq0QPfu3REbGwt7kZSUpMotDaC9+vPPPzFixAhs27YN69atQ0ZGBrp166bqZi9kMbe33noL4eHh2LlzJ+666y7cf//96m+atGPvbYRR2gd7bCPYPuiDEdoHTdoIyQpFtlu5cqXJycnJlJ6ebrJn77zzjqlWrVome/T555+b/Pz8TPagdevWphEjRuTez8rKMlWtWtU0bdo0kz2SU8mKFStM9i42NlbV5c8//zTZs/Lly5s++eQTrYtBBmsj7Ll9sKc2gu2DPhmlfSjpNoIjFsXg0qVLWLx4sRpqdXNzgz2Lj4+Hv7+/1sUwNLl6JlcOunTpkrvP2dlZ3d+6daumZXN08v9f2OvfQFZWFpYuXaquqMlwN+mDUdoItg8lj+2Dftl7+1BabQQ7FjZ46aWX4OPjgwoVKiAyMhIrV66EPTt27BhmzZqFp556SuuiGNqFCxfUH3dAQEC+/XL//PnzmpXL0cm0j9GjR6N9+/Zo2rQp7Mm+fftQpkwZtfDR008/jRUrVqBx48ZaF8vhGamNYPtQOtg+6JM9tw+l3UawY5HH+PHjVZDRjTaZd2o2btw47Nq1C2vXroWLiwsGDRokU8tgb/UQZ8+eRY8ePdQ81GHDhsEe60BkC5lLu3//fnU1x940aNAAu3fvxt9//63mkQ8ePBgHDx7UuliGY4Q2wgjtg2AbQaXJntuH0m4juPJ2HnFxcbh48eINj6lduzbc3d2v2x8VFYXg4GBs2bJF8ykI1tZDMpV06tQJt99+OxYuXKiGXe3xs5CyyxWFK1euQO9D3ZKd5Ntvv1VZJszkD13Kbo9XNaURlysgeetjT0aOHKned8lkIllw7J1Mm5AsPhJ4S8XHCG2EEdoHI7cRbB/0x2jtQ0m3Ea7F/ox2rFKlSmor6jCZSEtLgz3VQ65ESfaS0NBQfP7557ppNGz5LPROGjp5v9evX597opX/P3JfTmBUeuS6yrPPPqsavQ0bNhim0ZD/T3o4FxmNEdoII7QPRm4j2D7oh1Hbh5JuI9ixKAIZStqxYwfuuOMOlC9fXqURfPnll1XvT+vRCmtIoyFXomrUqIF3331XXQEyCwwMhL2QucsSHCk/ZW6qDPeJunXrqjmFeiSpBOUKVFhYGFq3bo2ZM2eqYKrHH38c9uLq1atq3rXZyZMn1XsvgW2Sv99ehreXLFmirkZJrnLzHGY/Pz+Vu98eTJgwAT179lTveWJioqqPNIK//vqr1kVzWEZoI4zSPthjG8H2QR+M0D5o0kaUSK4pg9u7d6+pc+fOJn9/f5OHh4epZs2apqefftoUFRVlsrfUe/JfwNJmTwYPHmyxDn/88YdJz2bNmmWqXr26yd3dXaUX3LZtm8meyPtr6X2Xz8NeFPb/X/427MUTTzxhqlGjhvp/VKlSJdPdd99tWrt2rdbFcmhGaCOM0j7YaxvB9kF7RmgftGgjGGNBREREREQ208+ESSIiIiIislvsWBARERERkc3YsSAiIiIiIpuxY0FERERERDZjx4KIiIiIiGzGjgUREREREdmMHQsiIiIiIrIZOxZERERERGQzdiyIiIiIiMhm7FgQEREREZHN2LEgIiIiIiKbsWNBVMri4uIQGBiIN998M3ffli1b4O7ujvXr12taNiIi0g7bB7J3TiaTyaR1IYgczerVq9GnTx/VYDRo0AAtW7bE/fffj/fff1/rohERkYbYPpA9Y8eCSCMjRozAb7/9hrCwMOzbtw87duyAh4eH1sUiIiKNsX0ge8WOBZFGUlJS0LRpU5w5cwbh4eFo1qyZ1kUiIiIdYPtA9ooxFkQaOX78OM6dO4fs7GycOnVK6+IQEZFOsH0ge8URCyINpKeno3Xr1mrurMyhnTlzphrurly5stZFIyIiDbF9IHvGjgWRBsaNG4dvv/0We/bsQZkyZdCxY0f4+flh1apVWheNiIg0xPaB7BmnQhGVsg0bNqgrUIsWLYKvry+cnZ3V7U2bNmHu3LlaF4+IiDTC9oHsHUcsiIiIiIjIZhyxICIiIiIim7FjQURERERENmPHgoiIiIiIbMaOBRERERER2YwdCyIiIiIishk7FkREREREZDN2LIiIiIiIyGbsWBARERERkc3YsSAiIiIiIpuxY0FERERERDZjx4KIiIiIiGzGjgUREREREcFW/wejDxaguzfAdQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9aecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Feed forward Layer helps the model to learn and generalize data with the conservation of the its shape and reducing complexity \n",
    "    of the neural network , it passes temporerly to a higher dimension in order to explore data in a much bigger space and learn more advanced features\n",
    "    than it returns it to the original shape after passing it through GELU activation function\n",
    "\"\"\"\n",
    "class FeedForward(nn.Module): \n",
    "    def __init__(self,cfg) : \n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"] , 4*cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"] , cfg[\"emb_dim\"])\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f73d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "batch = torch.randn([2,3,768])\n",
    "out = ffn(batch)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "372c4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    the residual (skip or even shortcut) connection is a method used for preventing Gradient Vanishing in the neural network (so to stabilize the training)\n",
    "    in fact , gradient may not get to the early layers , so updates in early layers are very small and can't learn during training as the later layers \n",
    "    skip connection is a way of creating a short path for the gradients to reach out early layers by skipping some intermediate layers to prevent vanishing.\n",
    "    it is done by connecting the input of an early layer with the output of more advanced layer\n",
    "\"\"\"\n",
    "\n",
    "class exampleDeepNN(nn.Module):\n",
    "    def __init__(self,layer_sizes,use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layer_sizes  = layer_sizes\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0] , layer_sizes[1]) , GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1] , layer_sizes[2]) , GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2] , layer_sizes[3]) , GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3] , layer_sizes[4]) , GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4] , layer_sizes[5]) , GELU())\n",
    "        ])\n",
    "    \n",
    "    def forward(self,x) : \n",
    "        for layer in self.layers : \n",
    "            layer_out = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_out.shape : \n",
    "                x = x + layer_out\n",
    "            else : \n",
    "                x = layer_out\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add12211",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_sizes = [3,3,3,3,3,1]\n",
    "sample_input = torch.tensor([[1.,0.,-1.]])\n",
    "torch.manual_seed(123)\n",
    "DNN_without_shortcuts = exampleDeepNN(layers_sizes , use_shortcut=False)\n",
    "def print_gradients(model,x):\n",
    "    out = model(x)\n",
    "    target = torch.tensor([0.])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(out , target)\n",
    "    loss.backward()\n",
    "    for name , param in model.named_parameters():\n",
    "        if \"weight\" in name : \n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e8b502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DHIA\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "print_gradients(DNN_without_shortcuts , sample_input)\n",
    "## early layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5da4f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.0014432319439947605\n",
      "layers.1.0.weight has gradient mean of 0.004846962168812752\n",
      "layers.2.0.weight has gradient mean of 0.0041389018297195435\n",
      "layers.3.0.weight has gradient mean of 0.00591512955725193\n",
      "layers.4.0.weight has gradient mean of 0.03265950828790665\n"
     ]
    }
   ],
   "source": [
    "DNN_with_shortcuts = exampleDeepNN(layers_sizes , use_shortcut=True)\n",
    "print_gradients(DNN_with_shortcuts , sample_input)\n",
    "## the gradient values stabilizes when we progress to the early layers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ad98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "class MultiHeadAttention(nn.Module) : \n",
    "    def __init__(self,d_in,d_out,context_length,dropout,num_heads,bias=False):\n",
    "        super().__init__()\n",
    "        assert(d_out % num_heads ==0 ) ,\"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.head_dim = d_out // num_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.w_k = nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.w_v = nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.out_proj = nn.Linear(d_out,d_out)\n",
    "        self.dropout  = nn.Dropout(dropout) \n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "            torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        b,num_tokens,d_embed= x.shape\n",
    "        \n",
    "        queries = self.w_q(x) ## (b , num_tokens , d_out)\n",
    "        #print(f\"queries :\\n {queries}\")\n",
    "        keys    = self.w_k(x) ## (b , num_tokens , d_out)\n",
    "        #print(f\"keys    : \\n {keys}\")\n",
    "        values  = self.w_v(x) ## (b , num_tokens , d_out)\n",
    "        #print(f\"values  : \\n {values}\")\n",
    "        ## (b , num_tokens , d_out) -------->  (b , num_tokens , num_heads , head_dim)\n",
    "        queries = queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        keys    = keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        values  = values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        #print(f\"queries after view :\\n {queries}\")\n",
    "        #print(f\"keys after view    :\\n {keys}\")\n",
    "        #print(f\"values after view  :\\n {values}\")\n",
    "        # (b , num_tokens , num_heads , head_dim) ------> (b , num_heads , num_tokens , head_dim)\n",
    "        ## in this case each head should be able to access all the tokens but with different embeddings (keys values splitted over the different heads)\n",
    "        keys    = keys.transpose(1,2) \n",
    "        queries = queries.transpose(1,2) \n",
    "        values  = values.transpose(1,2) \n",
    "        #print(f\"queries after transpose :\\n {queries}\")\n",
    "        #print(f\"keys after transpose    :\\n {keys}\")\n",
    "        #print(f\"values after transpose  :\\n {values}\")\n",
    "        attn_scores = queries @ keys.transpose(-1,-2)\n",
    "        #print(f\"Attention Scores : \\n {attn_scores}\")\n",
    "        mask_bool = self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        attn_scores_masked = attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
    "        #print(f\"Attention Scores masked : \\n {attn_scores_masked}\")\n",
    "        attn_weights = F.softmax(attn_scores_masked / keys.shape[-1]**0.5,dim=-1)\n",
    "        #print(f\"Attention Weights : \\n {attn_weights}\")\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context = ( attn_weights @ values ).transpose(1,2)# (b , num_heads , num_tokens , head_dim) ------> (b , num_tokens , num_heads , head_dim) \n",
    "        \n",
    "        context = context.contiguous().view(b,num_tokens,self.d_out)\n",
    "        \n",
    "        context = self.out_proj(context) # optional linear projection layer \n",
    "        \n",
    "        return context\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3913137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.MHattention = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.layer_norm_1 = LayerNorm(emb_dim=cfg['emb_dim'])\n",
    "        self.layer_norm_2 = LayerNorm(emb_dim=cfg['emb_dim'])\n",
    "        self.ffn          = FeedForward(cfg)\n",
    "        self.dropout      = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        \n",
    "    def forward(self,x) : \n",
    "        res_1 = x \n",
    "        x = self.layer_norm_1(x)\n",
    "        x = self.MHattention(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + res_1\n",
    "        \n",
    "        res_2 = x \n",
    "        \n",
    "        x = self.layer_norm_2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + res_2\n",
    "        \n",
    "        return x \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceff8e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3374, -0.1778, -0.3035,  ..., -0.3181, -1.3936,  0.5226],\n",
      "         [ 0.2579,  0.3420, -0.8168,  ..., -0.4098,  0.4978, -0.3721],\n",
      "         [ 0.7957,  0.5350,  0.9427,  ..., -1.0749,  0.0955, -1.4138],\n",
      "         [-0.0312,  1.6913, -2.2380,  ...,  0.2379, -1.1839, -0.3179]],\n",
      "\n",
      "        [[ 0.4279,  1.1632, -0.8327,  ...,  0.1802,  0.1917,  0.8713],\n",
      "         [-0.4334, -0.5095, -0.7118,  ...,  0.8329,  0.2992,  0.2496],\n",
      "         [-1.4580, -0.4094, -0.5215,  ..., -0.2644, -1.1221,  1.0535],\n",
      "         [-0.6634, -0.8472,  0.2937,  ..., -0.0461, -0.5843,  0.5808]]])\n",
      "\n",
      "Input shape  torch.Size([2, 4, 768])\n",
      "output shape torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.randn(2,4,768)\n",
    "print(x)\n",
    "block = TransformerBlock(cfg=GPT_CONFIG_124M)\n",
    "out = block(x)\n",
    "print(f\"\\nInput shape  {x.shape}\")\n",
    "print(f\"output shape {out.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768c967",
   "metadata": {},
   "source": [
    "GPT2-Like Model architecture (full working version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "891bea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@ Overview of the model architecture @@@@@ \n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb    = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
    "        self.pos_emb    = nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
    "        self.drop_emb   = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"] , cfg[\"vocab_size\"],bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self,in_idx) : \n",
    "        batch_size , seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len,device=in_idx.device))\n",
    "        \n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fcddf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  batch shape :  torch.Size([2, 4])\n",
      "Output batch shape :  torch.Size([2, 4, 50257])\n",
      "Input \n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "Model Output \n",
      " tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " 50257 is the vocabulary size of the tokenizer \n",
    " we passed 2 input texts with sequence length of 4 \n",
    " after the embedding we will have an input of shape [2,4,768] which will propagate along the transformer block\n",
    " after the transformer block w have a final Normalization Layer and a Linear outout layer that will transfer the transformer block\n",
    " output into a higher dimensional space resulting in a shape of [2,4,50257] with 50257 the vocabulary size of the tokenizer    \n",
    "\"\"\"\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch_test)\n",
    "print(\"Input  batch shape : \",batch_test.shape)\n",
    "print(\"Output batch shape : \",out.shape)\n",
    "print(f\"Input \\n\",batch_test)\n",
    "print(f\"Model Output \\n\",out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f62cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of parameters  : 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total Number of parameters  : {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9db3be4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 768])\n",
      "torch.Size([1024, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): \n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26599c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Token Embedding Layer : torch.Size([50257, 768])\n",
      "Shape of the Linear Output Layer   : torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the Token Embedding Layer : {model.tok_emb.weight.shape}\")\n",
    "print(f\"Shape of the Linear Output Layer   : {model.out_head.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fa1cd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters in GPT2 : 124,412,160\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   In GPT2 , the parameters of the final linear layer are the same as the parameters of the token embedding layer [50257,768]\n",
    "   training only happens in the token embedding layer and the same weights are used in the final Linear Layer.\n",
    "   This is called Weight Tying , it reduces the overall memory footprint of the model and its computational complexity  \n",
    "\"\"\"\n",
    "\n",
    "total_params_GPT2 = sum(p.numel() for p in model.parameters()) - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Total number of trainable parameters in GPT2 : {total_params_GPT2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74b636af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of memory in Mbs needed for our 163M params model : 621.83 MB \n"
     ]
    }
   ],
   "source": [
    "## Memory requirement for 163 million params model\n",
    "total_size_bs = 163009536 * 4\n",
    "total_size_mbs = total_size_bs / (1024*1024)\n",
    "print(f\"Total amount of memory in Mbs needed for our 163M params model : {total_size_mbs:.2f} MB \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c610815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_XL = {\n",
    "\"vocab_size\": 50257, # Vocabulary size\n",
    "\"context_length\": 1024, # Context length ==> after 1024 tokens the model can predict the next token \n",
    "\"emb_dim\": 1600, # Embedding dimension\n",
    "\"n_heads\": 25, # Number of attention heads\n",
    "\"n_layers\": 48, # Number of layers\n",
    "\"drop_rate\": 0.1, # Dropout rate\n",
    "\"qkv_bias\": False # Query-Key-Value bias\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_XL)\n",
    "out = model(batch_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71387d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of parameters  : 1,637,792,000\n",
      "Total amount of memory in GBs needed for our 163M params model : 6.10 GB \n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total Number of parameters  : {total_params:,}\")\n",
    "\n",
    "total_size_bs = total_params * 4\n",
    "total_size_gbs = total_size_bs / (1024*1024*1024)\n",
    "print(f\"Total amount of memory in GBs needed for our 163M params model : {total_size_gbs:.2f} GB \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984bf5c1",
   "metadata": {},
   "source": [
    "Generating text fom the GPT model output od size [batch_size , num_tokens , vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aace8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_token(model,idx,max_new_tokens,context_size) : \n",
    "    for _ in range(max_new_tokens) : \n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) ## logits will be of shape [batch_size , num_tokens , vocab_size]\n",
    "        \n",
    "        logits = logits[:,-1,:] ## we need only to focus on the last time step (which correspond to the position of the next token to predict)\n",
    "        ## logits is now of shape [batch_size , vocab_size]\n",
    "        probs  = F.softmax(logits,dim=-1) ## we want the softmax to be calculated over the 50257 values / [batch_size , 1]\n",
    "        idx_next = torch.argmax(probs,dim=-1,keepdim=True)\n",
    "        idx = torch.cat((idx , idx_next) , dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc7ca06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded input shape : torch.Size([1, 5])\n",
      "encoded input :  tensor([[15496,   837,   314,   716,   220]])\n",
      "Model Output  : tensor([[15496,   837,   314,   716,   220, 21458, 26203,  4358,  9408, 19674,\n",
      "         22966]])\n",
      "Output length : 11\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello , I am \"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) ## unsqueeze(0) to add the batch dim \n",
    "\n",
    "print(f\"encoded input shape : {encoded_tensor.shape}\")\n",
    "print(f\"encoded input :  {encoded_tensor}\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "out = generate_next_token(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Model Output  : {out}\")\n",
    "print(f\"Output length : {len(out[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "757f7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result : Hello , I am  Boo Darrenternal attitude Gren stint\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(f\"Final result : {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309f039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
